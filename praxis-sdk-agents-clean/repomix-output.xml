This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
.devcontainer/
  devcontainer.json
  docker-compose.yml
  Dockerfile
.github/
  ISSUE_TEMPLATE/
    bug_report.md
    config.yml
    feature_request.md
  workflows/
    release.praxis-sdk-agents.yml
    release.python-agent.yml
    reusable.publish-agent.yml
    reusable.publish-docker.yml
    reusable.publish-python.yml
    reusable.release.yml
    tests.praxis-sdk-agents.yml
  CODEOWNERS
  PULL_REQUEST_TEMPLATE.md
docs/
  architecture/
    images/
      agent-container.svg
      agent-context.svg
    agent-container.md
    agent-container.puml
    agent-context.puml
    README.md
    sequence.md
  CONTRIBUTING.md
praxis_sdk/
  agents/
    ai_registry/
      __init__.py
      client.py
      config.py
    card/
      __init__.py
      builder.py
      config.py
      models.py
    domain_knowledge/
      __init__.py
      client.py
      config.py
    langchain/
      langfuse/
        config.py
      __init__.py
      config.py
      executor.py
    memory/
      __init__.py
      client.py
      config.py
    orchestration/
      __init__.py
      config.py
      models.py
      runner.py
      utils.py
    p2p/
      libp2p/
        __init__.py
        node.py
        utils.py
      __init__.py
      config.py
      const.py
      handlers.py
      manager.py
      utils.py
    prompt/
      __init__.py
      builder.py
      config.py
      const.py
      parser.py
      utils.py
    templates/
      chatter/
        chat.txt.j2
      intenter/
        classify_intent_examples.txt.j2
        classify_intent.txt.j2
      planner/
        generate_plan_examples.txt.j2
        generate_plan.txt.j2
      reconfigurator/
        update_config_examples.txt.j2
        update_config.txt.j2
      system_prompt.txt.j2
    workflows/
      __init__.py
      config.py
      runner.py
    abc.py
    bootstrap.py
    config.py
    const.py
    models.py
    ray_entrypoint.py
    utils.py
tests/
  p2p/
    libp2p/
      test_p2pnode.py
      test_p2putils.py
    conftest.py
    test_p2p_manager.py
  test_sdk.py
.bumpversion.toml
.env.example
.gitignore
.pre-commit-config.yaml
CHANGELOG.md
CODE_OF_CONDUCT.md
docker-compose.yaml
Dockerfile
entrypoint.py
LICENSE
pyproject.toml
README.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".devcontainer/devcontainer.json">
// For format details, see https://aka.ms/devcontainer.json. For config options, see the
// README at: https://github.com/devcontainers/templates/tree/main/src/docker-outside-of-docker-compose
{
	"name": "Docker from Docker Compose",
	"dockerComposeFile": "docker-compose.yml",
	"service": "app",
	"workspaceFolder": "/workspaces/${localWorkspaceFolderBasename}",

	// Use this environment variable if you need to bind mount your local source code into a new container.
	"remoteEnv": {
		"LOCAL_WORKSPACE_FOLDER": "${localWorkspaceFolder}"
	},

	"features": {
		"ghcr.io/devcontainers/features/docker-outside-of-docker:1": {
			"version": "latest",
			"enableNonRootDocker": "true",
			"moby": "true"
		}
	}
	// Use 'forwardPorts' to make a list of ports inside the container available locally.
	// "forwardPorts": [],

	// Use 'postCreateCommand' to run commands after the container is created.
	// "postCreateCommand": "docker --version",

	// Uncomment to connect as root instead. More info: https://aka.ms/dev-containers-non-root.
	// "remoteUser": "root"
}
</file>

<file path=".github/ISSUE_TEMPLATE/bug_report.md">
---
name: Bug Report
about: Create a report to help us improve
title: '[BUG] '
labels: 'bug'
assignees: ''
---

## Bug Description

A clear and concise description of what the bug is.

## Reproduction Steps

Steps to reproduce the behavior:

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error

## Expected Behavior

A clear and concise description of what you expected to happen.

## Actual Behavior

A clear and concise description of what actually happened.

## Environment

- OS: [e.g. macOS 13.0, Ubuntu 22.04]
- Python version: [e.g. 3.10.8]
- praxis SDK Core version: [e.g. 1.2.3]
- Poetry version: [e.g. 1.4.2]

## Additional Context

Add any other context about the problem here.

## Screenshots

If applicable, add screenshots to help explain your problem.

## Error Logs

```
Paste any relevant error logs here
```

## Possible Solution

If you have suggestions on how to fix the bug, please describe them here.
</file>

<file path=".github/ISSUE_TEMPLATE/config.yml">
blank_issues_enabled: false
contact_links:
  - name: GitHub Discussions
    url: https://github.com/prxs-ai/praxis-sdk-agents/discussions
    about: Please ask and answer questions here.
  - name: Documentation
    url: https://github.com/prxs-ai/praxis-sdk-agents/blob/main/docs/CONTRIBUTING.md
    about: Check our contributing guide for development workflows.
</file>

<file path=".github/ISSUE_TEMPLATE/feature_request.md">
---
name: Feature Request
about: Suggest an idea for this project
title: '[FEATURE] '
labels: 'enhancement'
assignees: ''
---

## Feature Description

A clear and concise description of what you want to happen.

## Problem Statement

Describe the problem this feature would solve.

## Proposed Solution

Describe the solution you'd like.

## Alternative Solutions

Describe any alternative solutions or features you've considered.

## Additional Context

Add any other context or screenshots about the feature request here.
</file>

<file path=".github/workflows/release.praxis-sdk-agents.yml">
name: Release - praxis-sdk-agents

on:
  push:
    tags:
      - "v*"

jobs:
  build:
    permissions:
      id-token: write
      contents: read
    uses: ./.github/workflows/reusable.publish-agent.yml
    with:
      path: .
      agent_name: praxis-sdk-agents
    secrets:
      OCI_REGISTRY_TOKEN: ${{ secrets.OCI_REGISTRY_TOKEN }}
      REGISTRY_TOKEN: ${{ secrets.REGISTRY_TOKEN }}
</file>

<file path=".github/workflows/reusable.release.yml">
name: Reusable - release new version

on:
    workflow_call:
      inputs:
        working_directory:
          required: true
          type: string
        part:
          required: true
          type: string
      secrets:
        RELEASE_TOKEN:
          required: true


jobs:
  release:
    # allow release only from main branch
    if: ${{ github.ref_name == 'main' }}
    defaults:
      run:
        working-directory: ${{ inputs.working_directory }}
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          persist-credentials: false
      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install bump-my-version

      - name: Release
        run: |
          git config --global user.name hyp0cr4t
          git config --global user.email "hyp0cr4t@users.noreply.github.com"
          git remote set-url origin https://x-access-token:${{ secrets.RELEASE_TOKEN }}@github.com/${{ github.repository }}
          bump-my-version bump --tag --commit ${{ inputs.part }}
          git push --follow-tags
</file>

<file path=".github/PULL_REQUEST_TEMPLATE.md">
## Description

Please include a summary of the changes and which issue is fixed. Include relevant motivation and context.

Fixes # (issue)

## Type of Change

Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] Documentation update

## Checklist

- [ ] My code follows the style guidelines of this project
- [ ] I have performed a self-review of my own code
- [ ] I have commented my code, particularly in hard-to-understand areas
- [ ] I have made corresponding changes to the documentation
- [ ] My changes generate no new warnings
- [ ] I have added tests that prove my fix is effective or that my feature works
- [ ] New and existing unit tests pass locally with my changes
- [ ] Any dependent changes have been merged and published in downstream modules
- [ ] Version bumped (if applicable)
- [ ] Changelog entry included
</file>

<file path="docs/architecture/images/agent-container.svg">
<?xml version="1.0" encoding="us-ascii" standalone="no"?><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" contentStyleType="text/css" height="601px" preserveAspectRatio="none" style="width:239px;height:601px;background:#FFFFFF;" version="1.1" viewBox="0 0 239 601" width="239px" zoomAndPan="magnify"><defs/><g><!--cluster agent--><g id="cluster_agent"><rect fill="none" height="588.72" rx="2.5" ry="2.5" style="stroke:#444444;stroke-width:1.0;stroke-dasharray:7.0,7.0;" width="226" x="7" y="7"/><text fill="#444444" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="87" x="76.5" y="44.4688">SDK Agent</text><text fill="#444444" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacing" textLength="53" x="93.5" y="59.4453">[system]</text></g><!--entity sdk--><g id="elem_sdk"><rect fill="#438DD5" height="116.5742" rx="2.5" ry="2.5" style="stroke:#3C7FC0;stroke-width:0.5;" width="166" x="35" y="78"/><text fill="#FFFFFF" font-family="sans-serif" font-size="12" font-style="italic" lengthAdjust="spacing" textLength="65" x="85.5" y="99.6016">&#171;container&#187;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="33" x="70.5" y="117.6016">SDK</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="5" x="103.5" y="117.6016">&#160;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="57" x="108.5" y="117.6016">Library</text><text fill="#FFFFFF" font-family="sans-serif" font-size="12" font-style="italic" lengthAdjust="spacing" textLength="46" x="95" y="132.5781">[Python]</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="4" x="116" y="148.6445">&#160;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="73" x="45" y="165.1328">Bootstraps</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="4" x="118" y="165.1328">&#160;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="39" x="122" y="165.1328">agent</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="4" x="161" y="165.1328">&#160;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="26" x="165" y="165.1328">and</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="59" x="61.5" y="181.6211">provides</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="4" x="120.5" y="181.6211">&#160;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="50" x="124.5" y="181.6211">utilities</text></g><!--entity runtime--><g id="elem_runtime"><rect fill="#438DD5" height="116.5742" rx="2.5" ry="2.5" style="stroke:#3C7FC0;stroke-width:0.5;" width="185" x="25.5" y="270.57"/><text fill="#FFFFFF" font-family="sans-serif" font-size="12" font-style="italic" lengthAdjust="spacing" textLength="65" x="85.5" y="292.1716">&#171;container&#187;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="49" x="56.5" y="310.1716">Agent</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="5" x="105.5" y="310.1716">&#160;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="69" x="110.5" y="310.1716">Runtime</text><text fill="#FFFFFF" font-family="sans-serif" font-size="12" font-style="italic" lengthAdjust="spacing" textLength="25" x="86" y="325.1481">[Ray</text><text fill="#FFFFFF" font-family="sans-serif" font-size="12" font-style="italic" lengthAdjust="spacing" textLength="4" x="111" y="325.1481">&#160;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="12" font-style="italic" lengthAdjust="spacing" textLength="35" x="115" y="325.1481">Serve]</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="4" x="116" y="341.2145">&#160;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="61" x="35.5" y="357.7028">Executes</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="4" x="96.5" y="357.7028">&#160;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="70" x="100.5" y="357.7028">workflows</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="4" x="170.5" y="357.7028">&#160;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="26" x="174.5" y="357.7028">and</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="62" x="57" y="374.1911">manages</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="4" x="119" y="374.1911">&#160;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="56" x="123" y="374.1911">memory</text></g><!--entity plugins--><g id="elem_plugins"><rect fill="#438DD5" height="116.5742" rx="2.5" ry="2.5" style="stroke:#3C7FC0;stroke-width:0.5;" width="195" x="22.5" y="463.15"/><text fill="#FFFFFF" font-family="sans-serif" font-size="12" font-style="italic" lengthAdjust="spacing" textLength="65" x="87.5" y="484.7516">&#171;container&#187;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="127" x="32.5" y="502.7516">Plugin/Adapter</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="5" x="159.5" y="502.7516">&#160;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="43" x="164.5" y="502.7516">Layer</text><text fill="#FFFFFF" font-family="sans-serif" font-size="12" font-style="italic" lengthAdjust="spacing" textLength="46" x="97" y="517.7281">[Python]</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="4" x="118" y="533.7945">&#160;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="53" x="59.5" y="550.2828">Custom</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="4" x="112.5" y="550.2828">&#160;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="34" x="116.5" y="550.2828">tools</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="4" x="150.5" y="550.2828">&#160;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="26" x="154.5" y="550.2828">and</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="76" x="38.5" y="566.7711">third-party</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="4" x="114.5" y="566.7711">&#160;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="83" x="118.5" y="566.7711">integrations</text></g><!--link sdk to runtime--><g id="link_sdk_runtime"><path d="M118,194.98 C118,218.86 118,238.5 118,262.36 " fill="none" id="sdk-to-runtime" style="stroke:#666666;stroke-width:1.0;"/><polygon fill="#666666" points="118,270.36,121,262.36,115,262.36,118,270.36" style="stroke:#666666;stroke-width:1.0;"/><text fill="#666666" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacing" textLength="54" x="119" y="237.1716">Initialize</text></g><!--link runtime to plugins--><g id="link_runtime_plugins"><path d="M118.61,387.55 C118.86,411.44 119.0662,431.0704 119.3162,454.9304 " fill="none" id="runtime-to-plugins" style="stroke:#666666;stroke-width:1.0;"/><polygon fill="#666666" points="119.4,462.93,122.316,454.899,116.3163,454.9619,119.4,462.93" style="stroke:#666666;stroke-width:1.0;"/><text fill="#666666" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacing" textLength="65" x="120.06" y="429.7516">HTTP/SDK</text><text fill="#666666" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacing" textLength="4" x="185.06" y="429.7516">&#160;</text><text fill="#666666" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacing" textLength="28" x="189.06" y="429.7516">calls</text></g><!--SRC=[NP1DJm9138Rl-olgdY0HvkB96w29Ham8u9cKdN5tmdnbfWEknlzkPp4OcLCxRP_sVM-qQqoM2g0Z2kbUY8YdQQkfo_kSL6oy8-LesdWhWa57sPf98cdqNYpk9glozVQw51OJgSXVkmLFe7OgJWFtLjMcvuhTpNrs4cC_mfPvjr1l7bvWLk9w35yLyBjCZf8y_7OizJxoLCtfggVEknBDlQT44KE2WGRe98JeZrgg19cqqQHLgiTNs9WTQQkOC2o6zJalo3Nsi57nE2IF7wh9nAYJZuTtuqzfs63HyRe4LbdF9rtJWycjTgbSEaHY9Z6mAR34NiN_2XOvaRT0tfipcpeTvIHWf1uqMzv69ErTqV1TLMjbpfxyANXsh16D_bJSKkgNqjyTJzljIXGN6pI6KJy0]--></g></svg>
</file>

<file path="docs/architecture/images/agent-context.svg">
<?xml version="1.0" encoding="us-ascii" standalone="no"?><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" contentStyleType="text/css" height="419px" preserveAspectRatio="none" style="width:522px;height:419px;background:#FFFFFF;" version="1.1" viewBox="0 0 522 419" width="522px" zoomAndPan="magnify"><defs/><g><!--entity user--><g id="elem_user"><rect fill="#08427B" height="100.9766" rx="2.5" ry="2.5" style="stroke:#073B6F;stroke-width:0.5;" width="94" x="198" y="7"/><text fill="#FFFFFF" font-family="sans-serif" font-size="12" font-style="italic" lengthAdjust="spacing" textLength="52" x="219" y="28.6016">&#171;person&#187;</text><image height="48" width="48" x="221" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAACMElEQVR4Xu2YvUrFQBCFb+kj+Ai+gq3Y2PgA+gCCtZ2V2AhqaSNiqY1gYWMjaCvXykoEKy21sLCNfELgMscksz8mWfDAB3Kuye7sTmYnmcwtbU9KRozSECOVla3T6uTqvrqZPlcPT68/XNw+VtvH19XC+sGe/f9UxIhl8/Cy+vj8qrpEYIsbR1N7fSxihDK/urvMKoeKHbH3ikGMEJi8Z9WbtH92lxyEGCHErLwVqWfvG4IYXkiBXGIn7f29iOGBAe0kUkTVsmN4EcMD255bdgwvYnigFOYW54cdx4MYHlIqT5Niy6oYHuzgORRbUsXwYAfPoV4DeHl7t+MnK/Y8EMMDzVlu9foQ5y6jFAU7hhcxvOSsRLH5D2J4KbqVqMlxoK3tnEevPogRAiuXUpFiD69ZxIghZidSV75GjFiYkGc3KMEpOW8RIxXed0kNJsrOAO0ypTfnxGvEKA0xSkMMD3zfIedJFQ4hCPlUwrX1daQWbURsprxsRBhNue1D5rc53JkVQwN9c21Wt+D20JxLjN7hpztahSwTi3RExLDlbhhCxm55PkWLMkrvrDBW73rUTYtSQu/aGQ4h0snNzBdD1wPWptrZDDBjL6tfiebBzbA2AUjg2NT3QYkBbrR9KTS/9YoC9eAxqeu0UI/eH21yiu7VzLSqApnIqxn8Af6TiA3A/A9Bn5+lV0xcMMWDoJs6qrakTo4a6OwZxqLa97YkxC1HzMkMzNQRtE3cFUAJilMY3OGTNL0NDLqIAAAAASUVORK5CYII=" y="31.1328"/><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="32" x="208" y="94.6016">End</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="5" x="240" y="94.6016">&#160;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="37" x="245" y="94.6016">User</text></g><!--entity thirdparty--><g id="elem_thirdparty"><rect fill="#686868" height="100.9766" rx="2.5" ry="2.5" style="stroke:#8A8A8A;stroke-width:0.5;" width="148" x="7" y="312.95"/><text fill="#FFFFFF" font-family="sans-serif" font-size="12" font-style="italic" lengthAdjust="spacing" textLength="105" x="28.5" y="334.5516">&#171;external_person&#187;</text><image height="48" width="48" x="57" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAACE0lEQVR4Xu2YMW/CMBCF++P6Y5iZmVFHZmZmZmbmzMzMzOypvkqW0L3GOdvXEEt90idVjyb22ZfzJR+bzeajZ8ToDTFaORwO4/V6HW+323i/338YhmE8n8/jbrf7sv/fihi1nE6n8fl8jnMisP1+P9jraxGjlO12+8kql4odsfeqQYwSmLxn1ad0uVyagxCjhJqVtyL17H1LEMMLKRAldtLe34sYHhjQTqJFVC07hhcxPLDt0bJjeBHDA6UwWpwfdhwPYnhoqTxTqi2rYniwg0eotqSK4cEOHqFFA3g8Hnb8ZtWeB2J4oDmL1qIPcXQZpSjYMbyI4SWyEtXmP4jhpetWIhFxoB2Px+rVBzFKYOVaKlLt4fWKGDXU7ETryifEqIUJeXaDEtyS8xYxWuF9l9RgouwM0C5TeiMnnhCjN8ToDTE88H2HnCdVOISg5FMJ16brSC3aiNr0EiMHE849qPyW8p1JERTwN9fOVSt+L+2JxPgNbhrZOsyJQLw7IoYlsmUoEbvp+RQpxivRXWep2PW5nRAjQe7aG75DpJOdmyuAuQduSeXaDjFgLaufxPNg55gNgFK4Nk090GJArta/S1Mv/WKAvXgNmnrtFCP6w22U6G7tXLsKYKqcivEfwB+p+wDczwAs2Xl6NfUFQwx4dxNnlWvqxEhQd9cgDtXc254YrxA1LzM0U+8gN3FXAD0gRm98A/FFFW2vidUFAAAAAElFTkSuQmCC" y="337.0828"/><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="96" x="17" y="400.5516">Third-Party</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="5" x="113" y="400.5516">&#160;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="27" x="118" y="400.5516">API</text></g><!--entity agent--><g id="elem_agent"><rect fill="#1168BD" height="52.9766" rx="2.5" ry="2.5" style="stroke:#3C7FC0;stroke-width:0.5;" width="107" x="191.5" y="183.98"/><text fill="#FFFFFF" font-family="sans-serif" font-size="12" font-style="italic" lengthAdjust="spacing" textLength="52" x="219" y="205.5816">&#171;system&#187;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="33" x="201.5" y="223.5816">SDK</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="5" x="234.5" y="223.5816">&#160;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="49" x="239.5" y="223.5816">Agent</text></g><!--entity ai_registry--><g id="elem_ai_registry"><rect fill="#1168BD" height="52.9766" rx="2.5" ry="2.5" style="stroke:#3C7FC0;stroke-width:0.5;" width="109" x="190.5" y="336.95"/><text fill="#FFFFFF" font-family="sans-serif" font-size="12" font-style="italic" lengthAdjust="spacing" textLength="52" x="219" y="358.5516">&#171;system&#187;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="17" x="200.5" y="376.5516">AI</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="5" x="217.5" y="376.5516">&#160;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="67" x="222.5" y="376.5516">Registry</text></g><!--entity relay--><g id="elem_relay"><rect fill="#1168BD" height="52.9766" rx="2.5" ry="2.5" style="stroke:#3C7FC0;stroke-width:0.5;" width="125" x="373.5" y="336.95"/><text fill="#FFFFFF" font-family="sans-serif" font-size="12" font-style="italic" lengthAdjust="spacing" textLength="52" x="410" y="358.5516">&#171;system&#187;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="43" x="383.5" y="376.5516">Relay</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="5" x="426.5" y="376.5516">&#160;</text><text fill="#FFFFFF" font-family="sans-serif" font-size="16" font-weight="bold" lengthAdjust="spacing" textLength="57" x="431.5" y="376.5516">Service</text></g><!--link user to agent--><g id="link_user_agent"><path d="M245,108.34 C245,133.59 245,155.19 245,175.81 " fill="none" id="user-to-agent" style="stroke:#666666;stroke-width:1.0;"/><polygon fill="#666666" points="245,183.81,248,175.81,242,175.81,245,183.81" style="stroke:#666666;stroke-width:1.0;"/><text fill="#666666" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacing" textLength="30" x="246" y="150.5816">Uses</text><text fill="#666666" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacing" textLength="4" x="276" y="150.5816">&#160;</text><text fill="#666666" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacing" textLength="20" x="280" y="150.5816">API</text></g><!--link agent to ai_registry--><g id="link_agent_ai_registry"><path d="M243.31,237.42 C242.78,246.73 242.26,257.31 242,266.95 C241.36,290.5 241.94,309.311 242.95,328.521 " fill="none" id="agent-to-ai_registry" style="stroke:#666666;stroke-width:1.0;"/><polygon fill="#666666" points="243.37,336.51,245.9458,328.3635,239.9541,328.6785,243.37,336.51" style="stroke:#666666;stroke-width:1.0;"/><text fill="#666666" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacing" textLength="54" x="243" y="279.5516">Discover</text><text fill="#666666" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacing" textLength="4" x="297" y="279.5516">&#160;</text><text fill="#666666" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacing" textLength="32" x="301" y="279.5516">tools</text><text fill="#666666" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacing" textLength="4" x="333" y="279.5516">&#160;</text><text fill="#666666" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacing" textLength="9" x="337" y="279.5516">&amp;</text><text fill="#666666" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacing" textLength="4" x="346" y="279.5516">&#160;</text><text fill="#666666" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacing" textLength="42" x="350" y="279.5516">agents</text></g><!--link agent to relay--><g id="link_agent_relay"><path d="M298.64,219.8 C330.71,227.28 370.29,241.23 397,266.95 C416.35,285.59 424.5748,307.3833 429.5948,328.6833 " fill="none" id="agent-to-relay" style="stroke:#666666;stroke-width:1.0;"/><polygon fill="#666666" points="431.43,336.47,432.5148,327.9951,426.6748,329.3715,431.43,336.47" style="stroke:#666666;stroke-width:1.0;"/><text fill="#666666" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacing" textLength="54" x="410.34" y="279.5516">Message</text><text fill="#666666" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacing" textLength="4" x="464.34" y="279.5516">&#160;</text><text fill="#666666" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacing" textLength="46" x="468.34" y="279.5516">routing</text></g><!--link agent to thirdparty--><g id="link_agent_thirdparty"><path d="M208.82,237.18 C196.78,246.2 183.51,256.66 172,266.95 C156.13,281.15 145.2742,291.8251 130.8842,307.0551 " fill="none" id="agent-to-thirdparty" style="stroke:#666666;stroke-width:1.0;"/><polygon fill="#666666" points="125.39,312.87,133.0648,309.1154,128.7036,304.9947,125.39,312.87" style="stroke:#666666;stroke-width:1.0;"/><text fill="#666666" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacing" textLength="28" x="173" y="279.5516">Tool</text><text fill="#666666" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacing" textLength="4" x="201" y="279.5516">&#160;</text><text fill="#666666" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacing" textLength="28" x="205" y="279.5516">calls</text></g><!--SRC=[LKz1ReD03Bpp2ZU7Yae1BZtrXf8SeZOI2iqPRS22bPPTP9kq-NszAb7BQUsPySpia_Mjcpi464GcVYiACbzvRsMOhpCZjS4BUidRC1QJCrxcqMKidRFNOlUQLH6wd3wAqR0WATJizC9OZvHFgasI2ec3JwFP5ZO7ty55nytBGZI7RqbbiDHDXkIkai-uP5NSeAoEggplQZwcfjScAgZtxr36-Hzb6yBUib1qA8zmNhO_2Q4paJp75sgacsrHwKI1fTqZG0lo4Xt91Lvdx2stuOO44e9ZUFuzvlN98_E4p0e1XLcixzUYzUVL3LhZd3hz0000]--></g></svg>
</file>

<file path="docs/architecture/agent-container.md">
# Agent Containers

The SDK agent service is composed of three primary containers working together at runtime.

- **SDK Library** – houses bootstrap code and configuration helpers. When the service starts, this layer instantiates the runtime and any adapters based on entry points.
- **Agent Runtime** – the core execution engine built on Ray Serve and LangChain. It handles plan generation, workflow execution, memory management and message processing.
- **Plugin/Adapter Layer** – a collection of adapters for tools or other agents. Each adapter exposes a simple interface and is invoked by the runtime when a workflow step requires external functionality.

At startup the SDK Library boots the Agent Runtime with the configured adapters. During request processing the Agent Runtime calls the relevant adapter (synchronously over HTTP or direct SDK call) to perform a tool action. Results flow back to the runtime which then returns a response to the caller.
</file>

<file path="docs/architecture/agent-container.puml">
@startuml
!include  https://raw.githubusercontent.com/plantuml-stdlib/C4-PlantUML/master/C4_Container.puml

System_Boundary(agent, "SDK Agent") {
    Container(sdk, "SDK Library", "Python", "Bootstraps agent and provides utilities")
    Container(runtime, "Agent Runtime", "Ray Serve", "Executes workflows and manages memory")
    Container(plugins, "Plugin/Adapter Layer", "Python", "Custom tools and third-party integrations")
}

Rel(sdk, runtime, "Initialize")
Rel(runtime, plugins, "HTTP/SDK calls")
@enduml
</file>

<file path="docs/architecture/agent-context.puml">
@startuml
!include  https://raw.githubusercontent.com/plantuml-stdlib/C4-PlantUML/master/C4_Container.puml

Person(user, "End User")
Person_Ext(thirdparty, "Third-Party API")
System(agent, "SDK Agent")
System(ai_registry, "AI Registry")
System(relay, "Relay Service")

Rel(user, agent, "Uses API")
Rel(agent, ai_registry, "Discover tools & agents")
Rel(agent, relay, "Message routing")
Rel(agent, thirdparty, "Tool calls")
@enduml
</file>

<file path="docs/architecture/README.md">
# Architecture Overview

This folder contains high level diagrams for the SDK agent. The context diagram shows how the agent fits inside the wider platform and who interacts with it. The container diagram focuses on the internal pieces that make up the running service.

## Context

- **End User** – interacts with the agent through the HTTP API to ask questions or issue commands.
- **SDK Agent** – the running service hosting the agent logic. It communicates with the AI Registry to discover other agents and tools and uses the Relay Service for peer‑to‑peer messages. When a task requires an external capability the agent invokes a Third‑Party API as a tool.
- **AI Registry** – catalog of available agents and tools. The SDK agent queries it to find the right component for a given goal.
- **Relay Service** – networking layer that connects agents together. Messages such as handoff requests pass through it.
- **Third‑Party API** – any external service the agent calls as part of a workflow, e.g., a weather service.
</file>

<file path="docs/architecture/sequence.md">
# Sequence Diagrams

The following diagrams outline typical interactions with the SDK agent.

- **bootstrapping.mmd** – shows how the agent initializes its workflow runner and connects to the relay when the service starts.

```mermaid
sequenceDiagram
    participant Bootstrap
    participant WorkflowRunner as Runner
    participant Relay

    Bootstrap->>Runner: start_daemon()
    Bootstrap->>Runner: run_background_workflows()
    Bootstrap->>Relay: start()
    Relay-->>Bootstrap: connected
    Bootstrap-->>Bootstrap: agent ready
```

- **tool-interaction.mmd** – depicts the agent receiving a user request and invoking an external tool to fulfil it.

```mermaid
sequenceDiagram
    participant User
    participant AgentAPI as Agent
    participant Tool

    User->>AgentAPI: user query
    AgentAPI->>Tool: call service
    Tool-->>AgentAPI: result
    AgentAPI-->>User: response
```

- **agent-handoff.mmd** – illustrates one agent delegating a request to another via the relay service and returning the result.

```mermaid
sequenceDiagram
    participant AgentA
    participant Relay
    participant AgentB

    AgentA->>Relay: handoff(goal, plan)
    Relay->>AgentB: deliver request
    AgentB->>Relay: result
    Relay->>AgentA: result
    AgentA-->>Caller: finalize
```


- **user-chat.mmd** – demonstrates the conversational flow where a user message is classified, triggers a tool call and the agent replies back.

```mermaid
sequenceDiagram
    participant User
    participant Agent
    participant Classifier
    participant Tool

    User->>Agent: message
    Agent->>Classifier: classify intent
    Classifier-->>Agent: intent
    Agent->>Tool: call tool
    Tool-->>Agent: response
    Agent-->>User: answer
```
</file>

<file path="praxis_sdk/agents/ai_registry/__init__.py">
from __future__ import annotations

from typing import TYPE_CHECKING

from praxis_sdk.agents.const import EntrypointGroup
from praxis_sdk.agents.utils import get_entrypoint

if TYPE_CHECKING:
    from praxis_sdk.agents.prompt.config import BasicPromptConfig


def ai_registry_builder(*args, **kwargs):
    config: BasicPromptConfig = get_entrypoint(EntrypointGroup.AI_REGISTRY_CONFIG_ENTRYPOINT).load()
    return get_entrypoint(EntrypointGroup.AI_REGISTRY_ENTRYPOINT).load()(config())
</file>

<file path="praxis_sdk/agents/ai_registry/client.py">
from typing import Any

import httpx
from tenacity import retry, retry_if_exception_type, stop_after_attempt, wait_exponential

from praxis_sdk.agents.ai_registry.config import AiRegistryConfig


class AiRegistryClient:
    def __init__(self, config: AiRegistryConfig):
        self.url = config.url
        self.timeout = config.timeout
        self.endpoints = config.endpoints

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10),
        retry=retry_if_exception_type((httpx.HTTPStatusError, httpx.RequestError)),
    )
    def post(self, endpoint: str, json: dict[str, Any]) -> dict:
        url = f"{self.url}{endpoint}"

        try:
            response = httpx.post(url, json=json, timeout=self.timeout)
            response.raise_for_status()
            return response.json()
        except httpx.HTTPStatusError as e:
            print(f"HTTP error: {e.response.status_code} - {e.response.text}")
        except httpx.RequestError as e:
            print(f"Request error: {e}")
        except Exception as e:
            print(f"Unexpected error: {e}")

        return {}


def ai_registry_client(config: AiRegistryConfig) -> AiRegistryClient:
    return AiRegistryClient(config=config)
</file>

<file path="praxis_sdk/agents/ai_registry/config.py">
from functools import lru_cache

import pydantic
from pydantic_settings import BaseSettings, SettingsConfigDict


class AiRegistryEndpoints(BaseSettings):
    find_agents: str = "/agents/find"
    find_tools: str = "/tools/find"


class AiRegistryConfig(BaseSettings):
    url: str = pydantic.Field("localhost")
    timeout: int = pydantic.Field(10)
    endpoints: AiRegistryEndpoints = AiRegistryEndpoints()

    model_config = SettingsConfigDict(
        env_file=".env",
        env_prefix="AI_REGISTRY_",
        env_file_encoding="utf-8",
        extra=pydantic.Extra.ignore,
    )


@lru_cache
def get_ai_registry_config() -> AiRegistryConfig:
    return AiRegistryConfig()  # type: ignore[misc]
</file>

<file path="praxis_sdk/agents/card/__init__.py">
from praxis_sdk.agents.const import EntrypointGroup
from praxis_sdk.agents.utils import get_entrypoint


def card_builder():
    return get_entrypoint(EntrypointGroup.CARD_ENTRYPOINT).load()()
</file>

<file path="praxis_sdk/agents/card/builder.py">
from typing import Annotated

from pydantic import Field

from praxis_sdk.agents.abc import (
    AbstractAgentCard,
    AbstractAgentInputModel,
    AbstractAgentOutputModel,
    AbstractAgentParamsModel,
    BaseAgentInputModel,
    BaseAgentOutputModel,
)
from praxis_sdk.agents.card.config import get_card_config
from praxis_sdk.agents.card.models import AgentCard, AgentSKill


class GoalHandleParamsModel(AbstractAgentParamsModel):
    goal: Annotated[str, Field(description="The goal to handle")]


class GoalHandleInputModel(AbstractAgentInputModel):
    context: Annotated[BaseAgentInputModel, Field(description="The context of the request")]


class GoalHandleOutputModel(AbstractAgentOutputModel):
    result: Annotated[BaseAgentOutputModel, Field(description="The result of the request")]


def add_handle_goal_skill() -> AgentSKill:
    return AgentSKill(
        id="handle-goal",
        name="Handle all requests",
        description="This skill handles all requests",
        path="/{goal}",
        params_schema=GoalHandleParamsModel,
        input_schema=GoalHandleInputModel,
        output_schema=GoalHandleOutputModel,
    )


def get_agent_card() -> AbstractAgentCard:
    config = get_card_config()
    return AgentCard(
        name=config.name,
        version=config.version,
        description=config.description,
        skills=[
            add_handle_goal_skill(),
        ],
    )
</file>

<file path="praxis_sdk/agents/card/models.py">
from typing import Any

from pydantic import BaseModel, Field, field_serializer, field_validator

from praxis_sdk.agents.abc import (
    AbstractAgentCard,
    AbstractAgentInputModel,
    AbstractAgentOutputModel,
    AbstractAgentParamsModel,
    AbstractAgentSkill,
)
from praxis_sdk.agents.utils import create_pydantic_model_from_json_schema


class AgentSKill(AbstractAgentSkill):
    id: str = Field(..., description="ID of the skill")
    name: str = Field(..., description="Name of the skill")
    description: str = Field(..., description="Description of the skill")
    path: str = Field(..., description="Path to the skill")
    params_model: type[AbstractAgentParamsModel] = Field(
        ..., description="Parameters for the skill", alias="params_schema"
    )
    method: str = Field(default="POST", description="HTTP method to use for skill")
    input_model: type[AbstractAgentInputModel] = Field(
        ..., description="Input model for the skill", alias="input_schema"
    )
    output_model: type[AbstractAgentOutputModel] = Field(
        ..., description="Output model for the skill", alias="output_schema"
    )

    @field_serializer("params_model", "input_model", "output_model", when_used="always")
    def create_models(self, model: BaseModel, _info) -> dict:
        return model.model_json_schema()

    @field_validator("params_model", mode="before")
    @classmethod
    def validate_params(cls, value: Any) -> BaseModel:
        if isinstance(value, dict):
            return create_pydantic_model_from_json_schema(
                "DynamicParamsModel", value, base_klass=AbstractAgentParamsModel
            )
        return value

    @field_validator("input_model", mode="before")
    @classmethod
    def validate_input(cls, value: Any) -> BaseModel:
        if isinstance(value, dict):
            return create_pydantic_model_from_json_schema(
                "DynamicInputModel", value, base_klass=AbstractAgentInputModel
            )
        return value

    @field_validator("output_model", mode="before")
    @classmethod
    def validate_output(cls, value: Any) -> BaseModel:
        if isinstance(value, dict):
            return create_pydantic_model_from_json_schema(
                "DynamicOutputModel", value, base_klass=AbstractAgentOutputModel
            )
        return value


class AgentCard(AbstractAgentCard):
    name: str = Field(..., description="Name of the agent")
    version: str = Field(..., description="Version of the agent")
    description: str = Field(..., description="Description of the agent")

    skills: list[AgentSKill] = Field(..., description="List of skills of the agent")
</file>

<file path="praxis_sdk/agents/domain_knowledge/__init__.py">
from __future__ import annotations

from typing import TYPE_CHECKING

from praxis_sdk.agents.const import EntrypointGroup
from praxis_sdk.agents.utils import get_entrypoint

if TYPE_CHECKING:
    from praxis_sdk.agents.prompt.config import BasicPromptConfig


def light_rag_builder(*args, **kwargs):
    config: BasicPromptConfig = get_entrypoint(EntrypointGroup.DOMAIN_KNOWLEDGE_CONFIG_ENTRYPOINT).load()
    return get_entrypoint(EntrypointGroup.DOMAIN_KNOWLEDGE_ENTRYPOINT).load()(config())
</file>

<file path="praxis_sdk/agents/domain_knowledge/client.py">
from typing import Any

import httpx
from tenacity import retry, retry_if_exception_type, stop_after_attempt, wait_exponential

from praxis_sdk.agents.domain_knowledge.config import LightRagConfig, retries

# ------  Retries --------- #
stop = stop_after_attempt(retries.stop_attempts)
wait = wait_exponential(
    multiplier=retries.wait_multiplier,
    min=retries.wait_min,
    max=retries.wait_max,
)


class LightRagClient:
    def __init__(self, config: LightRagConfig):
        self.url = config.url
        self.timeout = config.timeout
        self.endpoints = config.endpoints

    @retry(
        stop=stop,
        wait=wait,
        retry=retry_if_exception_type((httpx.HTTPStatusError, httpx.RequestError)),
    )
    def post(self, endpoint: str, json: dict[str, Any]) -> dict:
        url = f"{self.url}{endpoint}"

        try:
            response = httpx.post(url, json=json, timeout=self.timeout)
            response.raise_for_status()
            return response.json()
        except httpx.HTTPStatusError as e:
            print(f"HTTP error: {e.response.status_code} - {e.response.text}")
        except httpx.RequestError as e:
            print(f"Request error: {e}")
        except Exception as e:
            print(f"Unexpected error: {e}")

        return {}

    @retry(
        stop=stop,
        wait=wait,
        retry=retry_if_exception_type((httpx.HTTPStatusError, httpx.RequestError)),
    )
    def get(self, endpoint: str, params: dict[str, Any]) -> dict:
        url = f"{self.url}{endpoint}"

        try:
            response = httpx.get(url, params=params, timeout=self.timeout)
            response.raise_for_status()
            return response.json()
        except httpx.HTTPStatusError as e:
            print(f"HTTP error: {e.response.status_code} - {e.response.text}")
        except httpx.RequestError as e:
            print(f"Request error: {e}")
        except Exception as e:
            print(f"Unexpected error: {e}")

        return {}


def light_rag_client(config: LightRagConfig) -> LightRagClient:
    return LightRagClient(config=config)
</file>

<file path="praxis_sdk/agents/domain_knowledge/config.py">
from functools import lru_cache

import pydantic
from pydantic_settings import BaseSettings, SettingsConfigDict


class KnowledgeBaseEndpoints(BaseSettings):
    query: str = "/knowledge/query"
    insert: str = "/knowledge/insert"


class Retries(BaseSettings):
    stop_attempts: int = 3
    wait_multiplier: int = 1
    wait_min: int = 4
    wait_max: int = 10


class LightRagConfig(BaseSettings):
    url: str = pydantic.Field("localhost")
    timeout: int = pydantic.Field(10)
    endpoints: KnowledgeBaseEndpoints = KnowledgeBaseEndpoints()

    model_config = SettingsConfigDict(
        env_file=".env",
        env_prefix="KNOWLEDGE_BASE_",
        env_file_encoding="utf-8",
        extra=pydantic.Extra.ignore,
    )


@lru_cache
def get_light_rag_config() -> LightRagConfig:
    return LightRagConfig()


retries: Retries = Retries()
</file>

<file path="praxis_sdk/agents/langchain/langfuse/config.py">
from functools import lru_cache

from pydantic import SecretStr
from pydantic_settings import BaseSettings


class BasicLangFuseConfig(BaseSettings):
    langfuse_secret_key: SecretStr
    langfuse_public_key: SecretStr
    langfuse_host: str


@lru_cache
def get_langfuse_config() -> BasicLangFuseConfig:
    return BasicLangFuseConfig()
</file>

<file path="praxis_sdk/agents/langchain/__init__.py">
from praxis_sdk.agents.const import EntrypointGroup
from praxis_sdk.agents.utils import get_entrypoint


def executor_builder():
    config = get_entrypoint(EntrypointGroup.AGENT_EXECUTOR_CONFIG_ENTRYPOINT).load()

    return get_entrypoint(EntrypointGroup.AGENT_EXECUTOR_ENTRYPOINT).load()(config())
</file>

<file path="praxis_sdk/agents/langchain/config.py">
from enum import Enum
from functools import lru_cache
from typing import Annotated

from pydantic import Field, SecretStr
from pydantic_settings import BaseSettings

from praxis_sdk.agents.langchain.langfuse.config import BasicLangFuseConfig


class ProviderEnum(str, Enum):
    OPENAI = "openai"
    DEEPSEEK = "deepseek"
    ANTHROPIC = "anthropic"

    def __str__(self):
        return self.value


# Base class for any LLM provider
class BaseLLMProviderConfig(BaseSettings):
    model: Annotated[str, Field(..., description="Model identifier to use for this provider")]


# OpenAI provider configuration
class OpenAIConfig(BaseLLMProviderConfig):
    api_key: SecretStr | None = None
    model: str = "gpt-4o"


# DeepSeek provider configuration
class DeepSeekConfig(BaseLLMProviderConfig):
    api_key: SecretStr | None = None
    model: str = "deepseek-chat"


# Anthropic provider configuration
class AnthropicConfig(BaseLLMProviderConfig):
    api_key: SecretStr | None = None
    model: str = "claude-3-7-sonnet-latest"


class BasicLangChainConfig(BaseSettings):
    provider: ProviderEnum = ProviderEnum.OPENAI
    openai: OpenAIConfig | None = None
    deepseek: DeepSeekConfig | None = None
    anthropic: AnthropicConfig | None = None

    openai_api_key: SecretStr
    openai_api_model: str = "gpt-4o"

    langfuse_enabled: bool = False

    class Config:
        arbitrary_types_allowed = True


class LangChainConfigWithLangfuse(BasicLangChainConfig, BasicLangFuseConfig):
    pass


@lru_cache
def get_langchain_config() -> BasicLangChainConfig:
    config = BasicLangChainConfig()

    # Initialize provider configs if they're None but selected as provider
    if config.provider == ProviderEnum.OPENAI and config.openai is None:
        config.openai = OpenAIConfig(api_key=config.openai_api_key)
    elif config.provider == ProviderEnum.DEEPSEEK and config.deepseek is None:
        config.deepseek = DeepSeekConfig()
    elif config.provider == ProviderEnum.ANTHROPIC and config.anthropic is None:
        config.anthropic = AnthropicConfig()

    if BasicLangChainConfig().langfuse_enabled:
        # Transfer the provider settings to the Langfuse config
        return LangChainConfigWithLangfuse(
            provider=config.provider,
            openai=config.openai,
            deepseek=config.deepseek,
            anthropic=config.anthropic,
        )

    return config
</file>

<file path="praxis_sdk/agents/langchain/executor.py">
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

from praxis_sdk.agents.abc import AbstractChatResponse, AbstractExecutor
from praxis_sdk.agents.langchain.config import BasicLangChainConfig, LangChainConfigWithLangfuse
from praxis_sdk.agents.prompt.parser import AgentOutputPlanParser


class ChatResponse(AbstractChatResponse):
    session_uuid: str


class LangChainExecutor(AbstractExecutor):
    def __init__(self, config: BasicLangChainConfig | LangChainConfigWithLangfuse):
        self.config = config

        self._callbacks = []
        if self.config.langfuse_enabled:
            self._init_langfuse_callback()

    def _init_langfuse_callback(self):
        from langfuse.callback import CallbackHandler

        self._callbacks.append(
            CallbackHandler(
                public_key=self.config.langfuse_public_key.get_secret_value(),
                secret_key=self.config.langfuse_secret_key.get_secret_value(),
                host=self.config.langfuse_host,
            )
        )

    def generate_plan(self, prompt: PromptTemplate, **kwargs) -> str:
        agent = ChatOpenAI(callbacks=self._callbacks, model=self.config.openai_api_model)
        output_parser = StrOutputParser()
        if "available_functions" in kwargs:
            agent.bind_tools(tools=[tool.openai_function_spec for tool in kwargs["available_functions"]])
            output_parser = AgentOutputPlanParser(tools=kwargs["available_functions"])

        kwargs["available_functions"] = "\n".join(
            [tool.render_function_spec() for tool in kwargs["available_functions"]]
        )

        chain = prompt | agent | output_parser

        return chain.invoke(input=kwargs)

    def chat(self, prompt: PromptTemplate, **kwargs) -> str:
        agent = ChatOpenAI(callbacks=self._callbacks, model=self.config.openai_api_model)
        output_parser = StrOutputParser()
        chain = prompt | agent | output_parser
        return chain.invoke(input=kwargs)

    def classify_intent(self, prompt: PromptTemplate, **kwargs) -> str:
        agent = ChatOpenAI(callbacks=self._callbacks, model=self.config.openai_api_model)
        output_parser = StrOutputParser()
        chain = prompt | agent | output_parser
        return chain.invoke(input=kwargs)

    def reconfigure(self, prompt: PromptTemplate, **kwargs) -> dict:
        agent = ChatOpenAI(callbacks=self._callbacks, model=self.config.openai_api_model)
        output_parser = JsonOutputParser()
        chain = prompt | agent | output_parser
        return chain.invoke(input=kwargs)


def agent_executor(config: BasicLangChainConfig | LangChainConfigWithLangfuse):
    return LangChainExecutor(config=config)
</file>

<file path="praxis_sdk/agents/memory/__init__.py">
from __future__ import annotations

from typing import TYPE_CHECKING

from praxis_sdk.agents.const import EntrypointGroup
from praxis_sdk.agents.utils import get_entrypoint

if TYPE_CHECKING:
    from praxis_sdk.agents.prompt.config import BasicPromptConfig


def memory_builder(*args, **kwargs):
    config: BasicPromptConfig = get_entrypoint(EntrypointGroup.MEMORY_CONFIG_ENTRYPOINT).load()
    return get_entrypoint(EntrypointGroup.MEMORY_ENTRYPOINT).load()(config())
</file>

<file path="praxis_sdk/agents/memory/client.py">
from typing import Any

from loguru import logger
from mem0 import Memory

from praxis_sdk.agents.memory.config import MemoryConfig


class MemoryClient:
    def __init__(self, config: MemoryConfig):
        self.memory = Memory.from_config(config.mem0_config)

    def store(self, key: str, interaction: list[Any]) -> None:
        try:
            logger.info(f"Storing interaction: {interaction} key: {key}")
            self.memory.add(interaction, run_id=key)
        except Exception as e:
            logger.error(f"Error storing interaction in Redis: {e}")

    def read(self, key: str, limit: int = 10) -> list[dict[str, Any]]:
        try:
            logger.info(f"Fetching all memories for key: {key}")
            return self.memory.get_all(run_id=key, limit=limit)
        except Exception as e:
            logger.error(f"Error retrieving interactions from Redis: {e}")
            return []


def memory_client(config: MemoryConfig) -> MemoryClient:
    return MemoryClient(config=config)
</file>

<file path="praxis_sdk/agents/memory/config.py">
from functools import lru_cache

from pydantic import Extra, Field
from pydantic_settings import BaseSettings, SettingsConfigDict


class Redis(BaseSettings):
    host: str = Field("localhost")
    port: int = Field(6379)
    db: int = Field(0)

    @property
    def url(self) -> str:
        return f"redis://{self.host}:{self.port}/{self.db}"

    model_config = SettingsConfigDict(
        env_file=".env",
        env_prefix="REDIS_",
        env_file_encoding="utf-8",
        extra=Extra.ignore,
    )


class MemoryConfig(BaseSettings):
    collection_name: str = Field("memory")
    embedding_model_dims: int = Field(1536)
    redis: Redis = Redis()

    @property
    def mem0_config(self) -> dict:
        return {
            "vector_store": {
                "provider": "redis",
                "config": {
                    "collection_name": self.collection_name,
                    "embedding_model_dims": self.embedding_model_dims,
                    "redis_url": self.redis.url,
                },
            },
            "version": "v1.1",
        }


@lru_cache
def get_memory_config() -> MemoryConfig:
    return MemoryConfig()
</file>

<file path="praxis_sdk/agents/orchestration/__init__.py">
from praxis_sdk.agents.const import EntrypointGroup
from praxis_sdk.agents.utils import get_entrypoint


def workflow_builder():
    config = get_entrypoint(EntrypointGroup.AGENT_WORKFLOW_CONFIG_ENTRYPOINT).load()

    return get_entrypoint(EntrypointGroup.AGENT_WORKFLOW_ENTRYPOINT).load()(config())
</file>

<file path="praxis_sdk/agents/orchestration/config.py">
from functools import lru_cache

from pydantic_settings import BaseSettings

from praxis_sdk.agents.orchestration.models import WorkflowSettings


class BasicWorkflowConfig(BaseSettings):
    WORKFLOWS_TO_RUN: dict[str, WorkflowSettings] = {}
    WORKFLOW_STEP_MAX_RETRIES: int = 5  # Задаю дефолт так как мне кажется, что она не настолько динамическая


@lru_cache
def get_workflow_config() -> BasicWorkflowConfig:
    return BasicWorkflowConfig()
</file>

<file path="praxis_sdk/agents/orchestration/models.py">
from pydantic import BaseModel


class WorkflowSettings(BaseModel):
    enabled: bool = True
</file>

<file path="praxis_sdk/agents/orchestration/utils.py">
import os
from typing import Any

import yaml

from praxis_sdk.agents.const import EntrypointGroup
from praxis_sdk.agents.utils import get_entrypoint


def determine_workflow_path(workflows_dir="workflows") -> str:
    # always exists
    candidate = get_entrypoint(EntrypointGroup.AGENT_ENTRYPOINT)
    pkg_path, _ = candidate.value.split(":", 1)

    # the workflows should be in the root of the package
    package_name = pkg_path.split(".")[0]

    # Get the package location on filesystem
    package = __import__(package_name)
    package_dir = str(package.__path__[0])

    return os.path.join(package_dir, workflows_dir)


def get_workflow_files() -> list[str]:
    workflow_dir = determine_workflow_path()
    workflow_files = []

    # Recursively find all yaml/yml files
    for root, _, files in os.walk(workflow_dir):
        for file in files:
            if file.endswith((".yaml", ".yml")):
                workflow_files.append(os.path.join(root, file))

    return workflow_files


def get_workflows_from_files() -> dict[str, dict[str, Any]]:
    wf_dict = {}
    for wf in get_workflow_files():
        try:
            wf_dict[wf] = parse_workflow_file(wf)
        except Exception as e:
            print("Failed to load workflow file %s: %s", wf, e)
            continue
    return wf_dict


def parse_workflow_file(wf_file) -> dict[str, Any]:
    with open(wf_file) as f:
        return yaml.safe_load(f)
</file>

<file path="praxis_sdk/agents/p2p/libp2p/__init__.py">
from .node import LibP2PNode

__all__ = ("LibP2PNode",)
</file>

<file path="praxis_sdk/agents/p2p/libp2p/utils.py">
import os
from base64 import b64decode
from pathlib import Path

from libp2p.crypto.ed25519 import Ed25519PrivateKey, create_new_key_pair
from libp2p.crypto.keys import KeyPair, PrivateKey
from loguru import logger


def load_or_create_node_key(seed_path: str) -> KeyPair:
    path = Path(seed_path)
    if path.exists():
        logger.info(f"Using the existing seed from: {seed_path}")
        seed = path.read_bytes()
    else:
        logger.info(f"Creating random seed: {seed_path}")
        seed = os.urandom(32)
        path.parent.mkdir(parents=True, exist_ok=True)
        path.write_bytes(seed)

    return create_new_key_pair(seed)


def decode_noise_key(key: str) -> PrivateKey:
    return Ed25519PrivateKey.from_bytes(b64decode(key))
</file>

<file path="praxis_sdk/agents/p2p/__init__.py">
from praxis_sdk.agents.const import EntrypointGroup
from praxis_sdk.agents.utils import get_entrypoint


def p2p_builder():
    from praxis_sdk.agents.p2p.config import get_p2p_config
    from praxis_sdk.agents.p2p.utils import init_keystore

    # init keystore first
    init_keystore(get_p2p_config().keystore_path)

    # load p2p entrypoint
    return get_entrypoint(EntrypointGroup.P2P_ENTRYPOINT).load()()  # type: ignore
</file>

<file path="praxis_sdk/agents/p2p/config.py">
from functools import lru_cache

import pydantic
from pydantic_settings import BaseSettings, SettingsConfigDict


class P2PConfig(BaseSettings):
    relay_addr: str = "/ip4/127.0.0.1/tcp/9000/p2p/RELAY_PEER_ID"
    keystore_path: str = "./keys"
    noise_key: str | None = None

    model_config = SettingsConfigDict(
        env_file=".env",
        env_prefix="P2P_",
        env_file_encoding="utf-8",
        extra=pydantic.Extra.ignore,
    )


@lru_cache
def get_p2p_config() -> P2PConfig:
    return P2PConfig()
</file>

<file path="praxis_sdk/agents/p2p/utils.py">
from pathlib import Path

from loguru import logger


def init_keystore(key_folder: str) -> Path:
    """Create keystore if it does not exist."""
    key_path = Path(key_folder)
    if not key_path.exists():
        try:
            key_path.mkdir()
        except Exception as e:
            logger.error(f"Failed to create keystore {e}")
        logger.info("Keystore created")

    return key_path.absolute()
</file>

<file path="praxis_sdk/agents/prompt/__init__.py">
from __future__ import annotations

from typing import TYPE_CHECKING

from praxis_sdk.agents.const import EntrypointGroup
from praxis_sdk.agents.utils import get_entrypoint

if TYPE_CHECKING:
    from praxis_sdk.agents.prompt.config import BasicPromptConfig


def prompt_builder():
    config: BasicPromptConfig = get_entrypoint(EntrypointGroup.AGENT_PROMPT_CONFIG_ENTRYPOINT).load()

    return get_entrypoint(EntrypointGroup.AGENT_PROMPT_ENTRYPOINT).load()(config())
</file>

<file path="praxis_sdk/agents/prompt/builder.py">
from jinja2 import Environment
from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate

from praxis_sdk.agents.abc import AbstractPromptBuilder
from praxis_sdk.agents.prompt.config import BasicPromptConfig
from praxis_sdk.agents.prompt.const import FINISH_ACTION, HANDOFF_ACTION
from praxis_sdk.agents.prompt.utils import get_environment


class PromptBuilder(AbstractPromptBuilder):
    def __init__(self, config: BasicPromptConfig, jinja2_env: Environment):
        self.config = config
        self.jinja2_env = jinja2_env

    def generate_plan_prompt(self, *args, system_prompt: str, **kwargs) -> ChatPromptTemplate:
        return ChatPromptTemplate.from_messages(
            [
                SystemMessagePromptTemplate.from_template(
                    self.jinja2_env.get_template(self.config.system_prompt_template).render(system_prompt=system_prompt)
                ),
                HumanMessagePromptTemplate.from_template(
                    self.jinja2_env.get_template(self.config.chat_template).render(
                        finish_action=FINISH_ACTION,
                        handoff_action=HANDOFF_ACTION,
                        examples=self.jinja2_env.get_template(self.config.generate_plan_examples_template).render(
                            finish_action=FINISH_ACTION,
                            handoff_action=HANDOFF_ACTION,
                        ),
                    )
                ),
            ]
        )

    def generate_chat_prompt(
        self, *args, system_prompt: str, user_prompt: str, context: str, **kwargs
    ) -> ChatPromptTemplate:
        return ChatPromptTemplate.from_messages(
            [
                SystemMessagePromptTemplate.from_template(
                    self.jinja2_env.get_template(self.config.system_prompt_template).render(system_prompt=system_prompt)
                ),
                HumanMessagePromptTemplate.from_template(
                    self.jinja2_env.get_template(self.config.chat_template).render(
                        context=context,
                        user_message=user_prompt,
                    )
                ),
            ]
        )

    def generate_intent_classifier_prompt(
        self, *args, system_prompt: str, user_prompt: str, **kwargs
    ) -> ChatPromptTemplate:
        return ChatPromptTemplate.from_messages(
            [
                SystemMessagePromptTemplate.from_template(
                    self.jinja2_env.get_template(self.config.system_prompt_template).render(system_prompt=system_prompt)
                ),
                HumanMessagePromptTemplate.from_template(
                    self.jinja2_env.get_template(self.config.intent_classifier_template).render(
                        user_message=user_prompt,
                        examples=self.jinja2_env.get_template(self.config.intent_classifier_examples_template),
                    )
                ),
            ]
        )

    def generate_reconfigure_prompt(
        self, *args, system_prompt: str, user_prompt: str, existing_config: str, **kwargs
    ) -> ChatPromptTemplate:
        return ChatPromptTemplate.from_messages(
            [
                SystemMessagePromptTemplate.from_template(
                    self.jinja2_env.get_template(self.config.system_prompt_template).render(system_prompt=system_prompt)
                ),
                HumanMessagePromptTemplate.from_template(
                    self.jinja2_env.get_template(self.config.update_config_template).render(
                        user_message=user_prompt,
                        existing_config=existing_config,
                        examples=self.jinja2_env.get_template(self.config.update_config_examples_template),
                    )
                ),
            ]
        )


def prompt_builder(config: BasicPromptConfig) -> PromptBuilder:
    return PromptBuilder(config, get_environment(config.template_path))
</file>

<file path="praxis_sdk/agents/prompt/const.py">
FINISH_ACTION = "return_answer_tool"
HANDOFF_ACTION = "handoff_tool"
</file>

<file path="praxis_sdk/agents/prompt/parser.py">
import re
from collections.abc import Sequence
from enum import Enum

import yaml
from langchain.agents.agent import AgentOutputParser
from langchain.schema import OutputParserException

from praxis_sdk.agents.models import InputItem, OutputItem, ParameterItem, ToolModel, Workflow, WorkflowStep


class RegexPattern(str, Enum):
    THOUGHT = r"Thought: ([^\n]*)"
    ACTION = r"\n*(\d+)\. (\w+)\((.*)\)(\s*#\w+\n)?"
    ID = r"\$\{?(\d+)\}?"
    YAML_PATTERN = r"```yaml\s+(.*?)\s+```"
    TEMPLATE_EXPR = r"\{\{(.*?)\}\}"


def default_dependency_rule(idx, args: str):
    matches = re.findall(RegexPattern.ID, args)
    numbers = [int(match) for match in matches]
    return idx in numbers


class AgentOutputPlanParser(AgentOutputParser, extra="allow"):
    """Planning output parser."""

    def __init__(self, tools: Sequence[ToolModel], **kwargs):
        super().__init__(**kwargs)
        self.tools = tools

    def parse(self, text: str) -> Workflow:
        # First try to extract YAML content
        yaml_match = re.search(RegexPattern.YAML_PATTERN, text, re.DOTALL)
        if not yaml_match:
            raise OutputParserException(f"Failed to parse YAML content from text: {text}")

        # If no YAML format found, fall back to the original parsing logic
        return self._parse_yaml_format(yaml_match.group(1))

    def _parse_yaml_format(self, yaml_content: str) -> Workflow:
        try:
            # Handle template expressions by temporarily replacing them
            template_expressions = {}

            def replace_template(match):
                placeholder = f"__TEMPLATE_{len(template_expressions)}__"
                template_expressions[placeholder] = match.group(0)
                return placeholder

            processed_content = re.sub(r"\{\{(.*?)\}\}", replace_template, yaml_content)

            # Parse YAML content
            workflow_data = yaml.safe_load(processed_content)

            # Convert back the template expressions
            def restore_templates(obj):
                if isinstance(obj, str):
                    for placeholder, template in template_expressions.items():
                        if placeholder in obj:
                            obj = obj.replace(placeholder, template)
                    return obj
                if isinstance(obj, list):
                    return [restore_templates(item) for item in obj]
                if isinstance(obj, dict):
                    return {k: restore_templates(v) for k, v in obj.items()}
                return obj

            workflow_data = restore_templates(workflow_data)

            # Convert to Workflow model
            return Workflow(
                name=workflow_data.get("name", "unnamed_workflow"),
                description=workflow_data.get("description", ""),
                thought=workflow_data.get("thought", ""),
                steps=[
                    WorkflowStep(
                        name=step.get("name", f"step_{i}"),
                        # should pick only the defined tools
                        tool=_find_tool(step.get("tool", ""), self.tools),
                        thought=step.get("thought", ""),
                        parameters=self._parse_parameters(step.get("parameters", [])),
                        inputs=self._parse_inputs(step.get("inputs", [])),
                        outputs=[
                            OutputItem(name=output_item.get("name", ""), value=output_item.get("value", None))
                            for output_item in step.get("outputs", [])
                        ],
                    )
                    for i, step in enumerate(workflow_data.get("steps", []))
                ],
                outputs=[
                    OutputItem(name=output_item.get("name", ""), value=output_item.get("value", None))
                    for output_item in workflow_data.get("outputs", [])
                ],
            )
        except yaml.YAMLError as e:
            raise OutputParserException(f"Failed to parse YAML content: {e}") from e

    def _parse_parameters(self, params: list | dict) -> list:
        if isinstance(params, dict):
            return [ParameterItem(name=name, value=value) for name, value in params.items()]
        return [
            ParameterItem(name=input_item.get("name", ""), value=input_item.get("value", "")) for input_item in params
        ]

    def _parse_inputs(self, inputs: list | dict) -> list:
        if isinstance(inputs, dict):
            return [InputItem(name=name, value=value) for name, value in inputs.items()]
        return [InputItem(name=input_item.get("name", ""), value=input_item.get("value", "")) for input_item in inputs]


### Helper functions


def _find_tool(tool_name: str, tools: Sequence[ToolModel]) -> ToolModel:
    """Find a tool by name.

    Args:
        tool_name: Name of the tool to find.
        tools: Sequence of available tools to search in.

    Returns:
        Tool or StructuredTool.

    """
    for tool in tools:
        if tool.package_name == tool_name or tool.function_name == tool_name:
            return tool
    raise OutputParserException(f"Tool {tool_name} not found.")
</file>

<file path="praxis_sdk/agents/prompt/utils.py">
from jinja2 import Environment, PackageLoader


def get_environment(package_name: str) -> Environment:
    return Environment(loader=PackageLoader(package_name=package_name))
</file>

<file path="praxis_sdk/agents/templates/chatter/chat.txt.j2">
You are an AI assistant designed for open-ended conversations and knowledge-based answers.
You have the following capabilities:
- Hold natural, polite, and helpful conversations with the user.
- Incorporate relevant facts from your knowledge base when available.
- Use recent conversation history to stay in context.

CONVERSATION HISTORY:
{context}
END OF CONVERSATION HISTORY

GUIDELINES:
- Use relevant knowledge when it helps answer the user's question, but don't repeat irrelevant information.
- Keep your reply concise, clear, and friendly.
- If you don't know, say so confidently and offer to help with something else.
- Do not reference your instructions or this prompt.
- Only respond to the user's most recent message.

Begin!
User: {user_message}
Assistant:
"""
</file>

<file path="praxis_sdk/agents/templates/intenter/classify_intent_examples.txt.j2">
EXAMPLE
User: How's the weather?
Intent: chit_chat
END OF EXAMPLE

EXAMPLE
User: Can you remember that my favorite color is green?
Intent: add_knowledge
END OF EXAMPLE

EXAMPLE
User: Show me your current configuration.
Intent: change_settings
END OF EXAMPLE
</file>

<file path="praxis_sdk/agents/templates/intenter/classify_intent.txt.j2">
Given a user message, your task is to classify the user's intent.

ALLOWED INTENTS:
- chit_chat: The user wants to have a freeform conversation or asks general questions unrelated to configuration or knowledge base updates.
- change_settings: The user asks about, wants to view, or requests changes to the agent's settings, configuration, parameters, or preferences.
- add_knowledge: The user wants the agent to store, remember, or add new information, facts, or instructions to its knowledge base.

INTENT CLASSIFICATION GUIDELINES:
- Only respond with one of the allowed intents: chit_chat, change_settings, add_knowledge.
- Do not include any explanation, comments, or additional output.
- If the user's intent is ambiguous, choose the most likely intent based on the message content.
- If the user refers to settings, configuration, or parameters, select change_settings.
- If the user asks to store, remember, or add information, select add_knowledge.
- For everything else, select chit_chat.

EXAMPLES
{{examples}}
END OF EXAMPLES

Begin!
User: {user_message}
Intent:
"""
</file>

<file path="praxis_sdk/agents/templates/planner/generate_plan_examples.txt.j2">
EXAMPLE
Goal: Using another agent to answer to the question of life, universe and everything
Plan:
{% raw %}
```yaml
name: handoff-answer-life-universe-everything
description: Returns the answer to the question of life, universe and everything via another agent
thought: This is a well-known question in science fiction "The Hitchhiker's Guide to the Galaxy" by Douglas Adams. The answer is 42. Let's return this answer.
steps:
  - name: handoff-answer-life-universe-everything
    tool: handoff_tool-to-another-agent
    thought: This step will be used to call another agent to get the answer to the question of life, universe and everything.
    parameters:
      - name: goal
        value: "Answer to the question of life, universe and everything"
    inputs: []
    outputs:
      - name: result
outputs:
  - name: answer
    value: \'{{{{steps.handoff-answer-life-universe-everything.outputs.result}}}}\'
```
{% endraw %}
END OF EXAMPLE
</file>

<file path="praxis_sdk/agents/templates/planner/generate_plan.txt.j2">
Given a goal, create a plan to solve it.

ACTIONS LIST:
{available_functions}
END OF ACTIONS LIST

PLAN GUIDELINES:
- Each plan must consist of 0 or more clearly defined steps using only the provided actions.
- Each step must strictly use one of the provided actions from ACTIONS LIST.
- Before using an action or constructing a plan, you must think how to use it right and provide a thought in the `thought` section.
- Action can have `parameters` optionally, which is not the same as `inputs`, and should be specified in `parameters` section.
- Every step must have a unique, descriptive name and should always have thought, inputs and outputs.
- Use '{{handoff_action}}' to handoff a task to another agent from the ACTIONS LIST.
- Do not introduce or use actions and agents other than those provided.
- Use `dependencies` to explicitly specify step execution order in multiple steps.
- Inputs can either be constants or outputs from previous steps (use  {{ '{{steps.step_name.outputs.output_name}}' }}).
- Do not include explanations or comments within the plan.
- Keep the plan as short as possible.

EXAMPLES
{{examples}}
END OF EXAMPLES

Begin!
Goal: {goal}
Plan:
</file>

<file path="praxis_sdk/agents/templates/reconfigurator/update_config_examples.txt.j2">
EXAMPLE
User: Please enable dark mode in the UI settings.
Existing Config:
{
    "ui": {
        "theme": "light",
        "font_size": "medium"
    }
}
Updated Config:
{
    "ui": {
        "theme": "dark",
        "font_size": "medium"
    }
}
END OF EXAMPLE

EXAMPLE
User: I want to turn off email notifications.
Existing Config:
{
    "notifications": {
        "email": true,
        "sms": false
    }
}
Updated Config:
{
    "notifications": {
        "email": false,
        "sms": false
    }
}
END OF EXAMPLE

EXAMPLE
User: Change the assistant's language to French.
Existing Config:
{
    "language": "English",
    "timezone": "UTC"
}
Updated Config:
{
    "language": "French",
    "timezone": "UTC"
}
END OF EXAMPLE
</file>

<file path="praxis_sdk/agents/templates/reconfigurator/update_config.txt.j2">
You are a configuration update assistant designed to help manage JSON-based agent configurations.
You receive the current configuration as JSON and a user request describing what should be updated.

CURRENT CONFIGURATION:
{existing_config}
END OF CONFIGURATION

USER REQUEST:
{user_message}
END OF USER REQUEST

YOUR TASK:
- Analyze the user's request.
- Identify exactly what needs to be changed in the configuration.
- Output ONLY the updated configuration as valid JSON.
- Do not include explanations or additional text, only the updated JSON.
- Preserve all existing fields unless the user explicitly asks to remove or change them.

Begin and return only the updated JSON configuration.
</file>

<file path="praxis_sdk/agents/templates/system_prompt.txt.j2">
{{system_prompt}}
</file>

<file path="praxis_sdk/agents/workflows/__init__.py">
from praxis_sdk.agents.const import EntrypointGroup
from praxis_sdk.agents.utils import get_entrypoint


def workflow_builder():
    config = get_entrypoint(EntrypointGroup.AGENT_WORKFLOW_CONFIG_ENTRYPOINT).load()

    return get_entrypoint(EntrypointGroup.AGENT_WORKFLOW_ENTRYPOINT).load()(config())
</file>

<file path="praxis_sdk/agents/workflows/config.py">
from functools import lru_cache

from pydantic_settings import BaseSettings


class BasicWorkflowConfig(BaseSettings):
    WORKFLOW_STEP_MAX_RETRIES: int = 5  # Задаю дефолт так как мне кажется, что она не настолько динамическая


@lru_cache
def get_workflow_config() -> BasicWorkflowConfig:
    return BasicWorkflowConfig()
</file>

<file path="praxis_sdk/agents/workflows/runner.py">
import uuid
from typing import Any

import ray
from ray import workflow
from ray.runtime_env import RuntimeEnv

from praxis_sdk.agents.const import EntrypointGroup
from praxis_sdk.agents.models import Task
from praxis_sdk.agents.utils import get_entry_points
from praxis_sdk.agents.workflows.config import BasicWorkflowConfig


@ray.remote
def generate_request_id() -> str:
    # Generate a unique idempotency token.
    return uuid.uuid4().hex


class DAGRunner:
    def __init__(self, config: BasicWorkflowConfig):
        self.config = config
        self.steps = {}

    def create_step(self, task: Task):
        """Create a remote function for a step."""

        @ray.workflow.options(checkpoint=True)
        @ray.remote(
            runtime_env=RuntimeEnv(pip=[f"{task.tool.name}=={task.tool.version}"]),
            max_retries=BasicWorkflowConfig.RAY_MAX_RETRIES,
            retry_exceptions=True,
        )
        def get_tool_entrypoint_wrapper(*args, **kwargs):
            entry_points = get_entry_points(EntrypointGroup.TOOL_ENTRYPOINT)
            try:
                tool = entry_points[task.tool.name].load()
            except KeyError as exc:
                raise ValueError(f"Tool {task.tool.name} not found in entry points") from exc

            return workflow.continuation(tool.bind(*args, **kwargs))

        return get_tool_entrypoint_wrapper

    def run(self, dag_spec: dict[int, Task], context: str | None) -> Any:
        """Run the DAG using Ray Workflows."""
        # Create remote functions for each step
        for _step_id, task in dag_spec.items():
            self.steps[task.task_id] = self.create_step(task)

        @ray.remote
        def workflow_executor(request_id: str) -> Any:
            step_results = {}

            # Find the last task to know when to return the final result
            last_task_id = max(dag_spec.keys())

            # Execute steps in order, handling dependencies
            for step_id, task in sorted(dag_spec.items()):
                task_id = task.task_id
                deps = task.dependencies

                # Gather inputs from dependencies
                inputs = {a["name"]: a["value"] for a in task.args}

                if deps:
                    dep_results = {}
                    for dep in deps:
                        if dep in step_results:
                            dep_results[dep] = step_results[dep]

                    # If we have dependency results, use them as inputs
                    if dep_results:
                        inputs = inputs.update(dep_results.values())

                # Execute step with dependencies
                step_func = self.steps[task_id]
                result = step_func.bind(**inputs)

                # Store result for dependencies
                step_results[task_id] = result

                # If this is the last step, return its result
                if step_id == last_task_id:
                    return workflow.continuation(result)

            # Return the last result as a fallback
            last_result = list(step_results.values())[-1] if step_results else None
            return workflow.continuation(last_result)

        # Start the workflow with options for durability
        return workflow.run(
            workflow_executor.bind(generate_request_id.bind()),
            workflow_id=f"dag-{uuid.uuid4().hex[:8]}",  # Unique ID for each workflow
            metadata={"dag_spec": str(dag_spec.keys())},  # Store metadata for debugging
        )


def dag_runner(config: BasicWorkflowConfig) -> DAGRunner:
    return DAGRunner(config)
</file>

<file path="praxis_sdk/agents/config.py">
import json
from functools import lru_cache

import pydantic
from pydantic_settings import BaseSettings, SettingsConfigDict


class BasicAgentConfig(BaseSettings):
    system_prompt: str = "Act as a helpful assistant. You are given a task to complete."
    agents: dict[str, str] = {}

    # Libp2p configuration
    registry_http_url: str = pydantic.Field("http://localhost:8081")
    registry_relay_peer_id: str = pydantic.Field("12D3KooWL1N7R2UDf9bVeyP6QR2hR7F1qXSkX5cv3H5Xz7N4L7kE")
    registry_relay_multiaddr_template: str = pydantic.Field("/ip4/127.0.0.1/tcp/4001/p2p/{}")
    agent_p2p_listen_addr: str = pydantic.Field("/ip4/0.0.0.0/tcp/0")
    agent_name: str = pydantic.Field("base-agent")

    model_config = SettingsConfigDict(env_file=".env", env_prefix="", extra="ignore")

    def __str__(self) -> str:
        """Serialize the config to a pretty JSON string for prompt usage."""
        return json.dumps(self.model_dump(), indent=2, ensure_ascii=False)


@lru_cache
def get_agent_config(**kwargs) -> BasicAgentConfig:
    return BasicAgentConfig(**kwargs)
</file>

<file path="praxis_sdk/agents/const.py">
from enum import Enum


class StrEnumMixIn(str, Enum):
    def __str__(self) -> str:
        return self.value


class ExtraQuestions(StrEnumMixIn):
    WHICH_SETTINGS = "Which settings would you like to change?"
    WHAT_INFO = "What information should I add to the knowledge base?"


class Intents(StrEnumMixIn):
    CHANGE_SETTINGS = "change_settings"
    ADD_KNOWLEDGE = "add_knowledge"
    CHIT_CHAT = "chit_chat"

    @property
    def all(self) -> set[str]:
        return {self.CHANGE_SETTINGS, self.ADD_KNOWLEDGE, self.CHIT_CHAT}


class EntrypointGroup(StrEnumMixIn):
    AGENT_ENTRYPOINT = "agent.entrypoint"
    TOOL_ENTRYPOINT = "tool.entrypoint"

    AGENT_PROMPT_CONFIG_ENTRYPOINT = "agent.prompt.config"
    AGENT_PROMPT_ENTRYPOINT = "agent.prompt.entrypoint"

    AGENT_EXECUTOR_CONFIG_ENTRYPOINT = "agent.executor.config"
    AGENT_EXECUTOR_ENTRYPOINT = "agent.executor.entrypoint"

    AGENT_WORKFLOW_CONFIG_ENTRYPOINT = "agent.workflow.config"
    AGENT_WORKFLOW_ENTRYPOINT = "agent.workflow.entrypoint"

    AI_REGISTRY_CONFIG_ENTRYPOINT = "ai.registry.config"
    AI_REGISTRY_ENTRYPOINT = "ai.registry.entrypoint"

    DOMAIN_KNOWLEDGE_CONFIG_ENTRYPOINT = "domain.knowledge.config"
    DOMAIN_KNOWLEDGE_ENTRYPOINT = "domain.knowledge.entrypoint"

    MEMORY_CONFIG_ENTRYPOINT = "memory.config"
    MEMORY_ENTRYPOINT = "memory.entrypoint"

    CARD_ENTRYPOINT = "card.entrypoint"

    P2P_ENTRYPOINT = "p2p.entrypoint"

    @property
    def group_name(self) -> str:
        return str(self)
</file>

<file path="CHANGELOG.md">
# Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [Unreleased]

### Added
- Initial project setup
- BaseAgent implementation with planning and execution capabilities
- Integration with AI Registry and LightRAG
- Redis-based memory storage
- Tool and agent discovery support
- GitHub repository structure standardization

### Changed

### Deprecated

### Removed

### Fixed

### Security
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2025 prxs-ai

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>

<file path=".devcontainer/docker-compose.yml">
version: '3'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile

    volumes:
      # Forwards the local Docker socket to the container.
      - /var/run/docker.sock:/var/run/docker-host.sock
      # Update this to wherever you want VS Code to mount the folder of your project
      - ../..:/workspaces:cached

    # Overrides default command so things don't shut down after the process ends.
    entrypoint: /usr/local/share/docker-init.sh
    command: sleep infinity

    # Uncomment the next four lines if you will use a ptrace-based debuggers like C++, Go, and Rust.
    # cap_add:
    #  - SYS_PTRACE
    # security_opt:
    #   - seccomp:unconfined

    # Use "forwardPorts" in **devcontainer.json** to forward an app port locally.
    # (Adding the "ports" property to this file will not forward from a Codespace.)
</file>

<file path=".github/workflows/reusable.publish-python.yml">
name: Reusable - Python Publish

on:
  workflow_call:
    inputs:
      path:
        required: true
        type: string
    secrets:
      REGISTRY_TOKEN:
        required: true

env:
  POETRY_REPOSITORIES_prxs_URL: https://agents.pypi.prxs.ai
  POETRY_HTTP_BASIC_prxs_USERNAME: prxs

jobs:
  build:
    defaults:
      run:
        working-directory: ${{ inputs.path }}
    permissions:
      id-token: write
      contents: read

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2

    - name: Set Up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'

    - name: Install deps
      run: |
        pip install poetry bump-my-version

    - name: Set branch version
      if: ${{ github.ref_type == 'branch' }}
      run: |
        VERSION=$(bump-my-version show current_version)
        # Replace both slashes and dots with hyphens to ensure a valid version string
        BRANCH=$(echo ${GITHUB_REF_NAME} | sed 's/[\/\.]/-/g' | awk '{print tolower($0)}')
        # Get short commit hash
        COMMIT_HASH=$(git rev-parse --short HEAD)
        echo "VERSION=$VERSION.dev0+$BRANCH.$COMMIT_HASH" >> $GITHUB_ENV
        bump-my-version bump --new-version "$VERSION.dev0+$BRANCH.$COMMIT_HASH" branch

    - name: Publish to registry
      run: |
        poetry publish --build -r prxs
      env:
        POETRY_HTTP_BASIC_prxs_PASSWORD: ${{ secrets.REGISTRY_TOKEN }}
</file>

<file path=".github/workflows/tests.praxis-sdk-agents.yml">
name: Tests - praxis-sdk-agents

on:
  push:
    branches-ignore:
      - "main"
    paths:
      - "praxis_sdk/**"
      - ".pre-commit-config.yaml"
      - "pyproject.toml"
  pull_request:
    types: [opened, reopened]

jobs:
  pre-commit:
    name: Run Pre-commit checks
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Poetry
        run: |
          curl -sSL https://install.python-poetry.org | python3 -
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Cache pre-commit hooks
        uses: actions/cache@v4
        with:
          path: ~/.cache/pre-commit
          key: ${{ runner.os }}-precommit-${{ hashFiles('.pre-commit-config.yaml') }}

      - name: Install dependencies
        run: poetry install --with dev

      - name: Run pre-commit
        run: poetry run pre-commit run --all-files --show-diff-on-failure

  test:
    name: Run Pytest for base agent
    runs-on: ubuntu-latest
    needs: pre-commit

    defaults:
      run:
        working-directory: .

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Poetry
        run: |
          curl -sSL https://install.python-poetry.org | python3 -
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Install dependencies
        run: poetry install

      - name: Run tests via Makefile
        run: |
          if [ -f "Makefile" ]; then
            poetry run make test
          elif [ -d "tests" ]; then
            poetry run pytest tests/ -v
          else
            echo "No tests found."
          fi
</file>

<file path=".github/CODEOWNERS">
# This file defines code owners for the praxis SDK Agents repository
# Code owners are automatically requested for review when somprxse opens a PR

* @hyp0cr4t @0xDevZip @ruthuwjwb

/docs/ @hyp0cr4t @ruthuwjwb @0xDevZip
*.md @hyp0cr4t @ruthuwjwb @0xDevZip
/README.md @hyp0cr4t @ruthuwjwb @0xDevZip

/pyproject.toml @hyp0cr4t @hexavor
/poetry.lock @hyp0cr4t @hexavor
/.github/ @hyp0cr4t @hexavor

/tests/ @hyp0cr4t @0xDevZip

/praxis_sdk/ @hyp0cr4t @0xDevZip @hexavor

/.github/workflows/ @hyp0cr4t @hexavor

/LICENSE @hyp0cr4t @0xDevZip @ruthuwjwb @hexavor
</file>

<file path="docs/CONTRIBUTING.md">
# Contributing to praxis SDK Agents

Thank you for your interest in contributing to praxis SDK Agents!

## GitHub Flow

We use GitHub Flow for our development process. This is a lightweight, branch-based workflow that supports teams and projects where deployments are made regularly.

### Workflow Steps

1. **Create a branch**: Create a new branch from `main` for your feature or bugfix
   ```bash
   git checkout -b feature/your-feature-name
   # or
   git checkout -b fix/your-bugfix-name
   ```

2. **Make changes**: Develop your feature or fix, committing changes regularly
   ```bash
   git add .
   git commit -m "feat: add new feature" # or "fix: resolve issue"
   ```

3. **Push to GitHub**: Push your branch to the repository
   ```bash
   git push origin feature/your-feature-name
   ```

4. **Open a Pull Request**: Create a PR from your branch to `main`
   - Use our PR template
   - Link related issues
   - Request reviews from maintainers

5. **Code Review**: Address feedback from reviewers
   - Make requested changes
   - Push additional commits
   - Respond to comments

6. **Merge**: Once approved and all checks pass, a maintainer will merge your PR

### Branch Naming Conventions

- `feature/` - for new features
- `fix/` - for bug fixes
- `docs/` - for documentation updates
- `chore/` - for maintenance tasks
- `refactor/` - for code refactoring

### Important Notes

- The `main` branch is protected and requires PR reviews
- All PRs must pass CI checks before merging
- Direct commits to `main` are not allowed

## Getting Started

1. Fork the repository
2. Clone your fork
3. Create a new branch for your feature
4. Make your changes
5. Submit a pull request

## Development Setup

```bash
# Clone the repository
git clone https://github.com/your-username/praxis-sdk-agents.git
cd praxis-sdk-agents

# Install dependencies
poetry install

# Run tests
poetry run pytest

# Run linting
poetry run ruff check .

# Run type checking
poetry run mypy .
```

## Code Style

- Follow PEP 8
- Use type hints where possible
- Write descriptive commit messages
- Add tests for new features

## Pull Request Process

1. Update the README.md with details of changes if needed
2. Update the CHANGELOG.md with your changes
3. The PR will be merged once you have the sign-off of at least one maintainer
</file>

<file path="praxis_sdk/agents/p2p/libp2p/node.py">
import os
from typing import TYPE_CHECKING

from libp2p import new_host
from libp2p.peer.peerinfo import info_from_p2p_addr
from libp2p.relay.circuit_v2.config import RelayConfig
from libp2p.relay.circuit_v2.protocol import CircuitV2Protocol
from libp2p.relay.circuit_v2.transport import CircuitV2Transport
from libp2p.security.noise.transport import PROTOCOL_ID as NOISE_PROTOCOL_ID
from libp2p.security.noise.transport import Transport as NoiseTransport
from loguru import logger
from multiaddr import Multiaddr

from praxis_sdk.agents.p2p.config import P2PConfig
from praxis_sdk.agents.p2p.const import PROTOCOL_CARD, PROTOCOL_HANDOFF
from praxis_sdk.agents.p2p.handlers import handle_card, handle_handoff
from praxis_sdk.agents.p2p.libp2p.utils import decode_noise_key, load_or_create_node_key

if TYPE_CHECKING:
    from libp2p.crypto.keys import KeyPair


class LibP2PNode:
    """Encapsulates all libp2p-related functionality."""

    def __init__(self, config: P2PConfig) -> None:
        self.config = config
        self.host = None
        self.shutdown_requested = False

        self._init_keypair()

    def _init_keypair(self, host_key_filename: str = "node.key"):
        self.keypair: KeyPair = load_or_create_node_key(os.path.join(self.config.keystore_path, host_key_filename))

    def _init_host(self):
        """Initialize libp2p host."""
        sec_opt = None

        if self.config.noise_key is not None:
            sec_opt = {
                NOISE_PROTOCOL_ID: NoiseTransport(
                    libp2p_keypair=self.keypair,
                    noise_privkey=decode_noise_key(self.config.noise_key),
                )
            }
        return new_host(key_pair=self.keypair, sec_opt=sec_opt)

    async def initialize(self):
        """Initialize the libp2p node."""
        self.host = self._init_host()
        self.host.set_stream_handler(PROTOCOL_CARD, handle_card)
        self.host.set_stream_handler(PROTOCOL_HANDOFF, handle_handoff)

        # Print host information
        logger.info(f"Node started with ID: {self.host.get_id()}")
        logger.info(f"Listening on: {self.host.get_addrs()}")

        config = RelayConfig(
            enable_stop=True,  # Accept relayed connections
            enable_client=True,  # Use relays for outbound connections
        )
        # Initialize the relay protocol
        self.protocol = CircuitV2Protocol(self.host)
        self.transport = CircuitV2Transport(self.host, self.protocol, config)

        return self.host

    async def connect_to_relay(self):
        """Connect to the relay node."""
        relay_addr = self.config.relay_addr
        logger.info(f"Connecting to relay at {relay_addr}")
        try:
            await self.host.connect(info_from_p2p_addr(Multiaddr(relay_addr)))  # type: ignore
            logger.info("Connected to relay successfully")
            return True
        except Exception as e:
            logger.error(f"Failed to connect to relay: {e}")
            return False

    async def setup_listener(self, nursery):
        """Set up the listener for incoming connections."""
        listener = self.transport.create_listener(lambda stream: handle_card(stream))  # type: ignore
        # start listening
        await listener.listen(None, nursery)  # type: ignore
        logger.info("Destination node ready to accept relayed connections")
</file>

<file path="praxis_sdk/agents/prompt/config.py">
from functools import lru_cache
from typing import Annotated

from jinja2 import PackageLoader
from pydantic import Field
from pydantic_settings import BaseSettings

from praxis_sdk.agents.const import EntrypointGroup
from praxis_sdk.agents.utils import get_entrypoint


def determine_template_path(default_path="praxis_sdk.agents") -> str:
    # always exists
    candidate = get_entrypoint(EntrypointGroup.AGENT_ENTRYPOINT)
    pkg_path, _ = candidate.value.split(":", 1)

    # the templates should be in the root of the package
    package_name = pkg_path.split(".")[0]

    # try to load the package path
    try:
        PackageLoader(package_name=package_name)
    except ValueError:
        return default_path

    return package_name


class BasicPromptConfig(BaseSettings):
    template_path: Annotated[str, Field(default_factory=determine_template_path)]

    # GENERATE_PLAN
    generate_plan_template: str = "planner/generate_plan.txt.j2"
    generate_plan_examples_template: str = "planner/generate_plan_examples.txt.j2"

    # CHAT
    chat_template: str = "chatter/chat.txt.j2"

    # CLASSIFY_INTENT
    intent_classifier_template: str = "intenter/classify_intent.txt.j2"
    intent_classifier_examples_template: str = "intenter/classify_intent_examples.txt.j2"

    # RECONFIGURE
    update_config_template: str = "reconfigurator/update_config.txt.j2"
    update_config_examples_template: str = "reconfigurator/update_config_examples.txt.j2"

    # SYSTEM PROMPT
    system_prompt_template: str = "system_prompt.txt.j2"


@lru_cache
def get_prompt_config() -> BasicPromptConfig:
    return BasicPromptConfig()
</file>

<file path="praxis_sdk/agents/models.py">
import uuid
from datetime import datetime
from typing import Any, Literal

from pydantic import BaseModel, Field, computed_field, field_validator, model_validator


class ToolModel(BaseModel):
    name: str
    version: str | None = None
    default_parameters: dict[str, Any] | None = Field(default_factory=dict)
    parameters_spec: dict[str, Any] | None = Field(default_factory=dict)
    openai_function_spec: dict[str, Any]

    @model_validator(mode="before")
    @classmethod
    def validate_name_and_version(cls, data: dict[str, Any]) -> dict[str, Any]:
        if "version" not in data or data["version"] is None:
            # If no version is specified, we assume the latest version
            data["name"], data["version"] = cls.parse_version_from_name(data["name"])
        return data

    @classmethod
    def parse_version_from_name(cls, name: str) -> tuple[str, str | None]:
        """Parse name and version from string in format package@version."""
        if "@" in name:
            package, version = name.split("@", 1)
            return package, version
        return name, None

    def render_pip_dependency(self) -> str:
        return f"{self.package_name}=={self.version}" if self.version else self.name

    @property
    def package_name(self) -> str:
        return self.name.replace("_", "-")

    @property
    def function_name(self) -> str:
        return self.openai_function_spec["function"]["name"]

    def render_function_spec(self) -> str:
        return f"""- {self.openai_function_spec["function"]["name"]}
    - description: {self.openai_function_spec["function"]["description"]}
    - parameters: {self.parameters_spec}
    - inputs: {self.openai_function_spec["function"]["parameters"]}
"""


class ParameterItem(BaseModel):
    name: str
    value: Any


class InputItem(BaseModel):
    name: str
    value: Any


class OutputItem(BaseModel):
    name: str


class WorkflowStep(BaseModel):
    name: str
    tool: ToolModel
    thought: str | None = None
    observation: str | None = None
    parameters: list[ParameterItem] = Field(default_factory=list)
    inputs: list[InputItem] = Field(default_factory=list)
    outputs: list[OutputItem] = Field(default_factory=list)

    @property
    def task_id(self) -> str:
        return f"{self.name}: {self.tool}"

    @field_validator("tool", mode="before")
    @classmethod
    def validate_tool(cls, v: Any) -> "ToolModel":
        if isinstance(v, str):
            return ToolModel(name=v, openai_function_spec={})
        return v

    @property
    def env_vars(self) -> dict[str, str]:
        d = {}
        if self.tool.default_parameters:
            # get default parameters
            d.update(self.tool.default_parameters)
        if "params" in d and isinstance(d["params"], dict):
            del d["params"]
            # replace with nested parameters
            # d['params'] = ",".join([f"{p.name}=\"{p.value}\"" for p in self.parameters])
            d.update({f"params__{p.name}": p.value for p in self.parameters})
        else:
            d.update({p.name: p.value for p in self.parameters})
        return d

    @property
    def args(self) -> dict[str, Any]:
        return {a.name: a.value for a in self.inputs}

    def get_thought_action_observation(self, *, include_action: bool = True, include_thought: bool = True) -> str:
        thought_action_observation = ""
        if self.thought and include_thought:
            thought_action_observation = f"Thought: {self.thought}\n"
        if include_action:
            tool_args = {inp.name: inp.value for inp in self.inputs}
            thought_action_observation += f"{self.name}({tool_args})\n"
        if self.observation is not None:
            thought_action_observation += f"Observation: {self.observation}\n"
        return thought_action_observation


class Workflow(BaseModel):
    id: str = Field(default_factory=lambda x: f"dag-{uuid.uuid4().hex[:8]}")
    name: str
    description: str
    thought: str | None = None
    parameters: list[Any] = Field(default_factory=list)
    steps: list[WorkflowStep]
    outputs: list[OutputItem] = Field(default_factory=list)


class ChatRequest(BaseModel):
    message: str
    action: str | None = None
    session_uuid: str | None = None


class ChatMessageModel(BaseModel):
    role: str = Field(..., description="Sender role: 'user' or 'assistant'")
    content: str = Field(..., description="Message content")
    timestamp: datetime | None = Field(default_factory=datetime.utcnow, description="Message timestamp")


class ChatContextModel(BaseModel):
    uuid: str = Field(..., description="Unique chat/session UUID")
    history: list[ChatMessageModel] = Field(default_factory=list, description="Chronological chat messages")


class MemoryModel(BaseModel):
    goal: str
    plan: dict[str, Any]
    result: dict[str, Any]
    context: dict[str, Any] | None = Field(default=None, description="Used when plan is provided")


class AgentModel(BaseModel):
    name: str
    description: str
    version: str
    peer_id: str | None = Field(default=None, description="P2P peer ID for direct delegation")

    @computed_field
    def endpoint(self) -> str:
        # TODO(team): Change this to the most appropriate way via route mapping from ai registry  # https://github.com/project/issues/123
        return f"http://{self.name}-serve-svc.praxis:8000"
        # return "http://localhost:8000"


class GoalModel(BaseModel):
    goal: str = Field(..., description="Goal to reach")


class QueryData(BaseModel):
    query: str = Field(..., description="Query to search for")
    mode: Literal["local", "global", "hybrid", "naive", "mix"] = Field(
        default="global",
        description="Specifies the retrieval mode:\n"
        "- 'local': Focuses on context-dependent information.\n"
        "- 'global': Utilizes global knowledge.\n"
        "- 'hybrid': Combines local and global retrieval methods.\n"
        "- 'naive': Performs a basic search without advanced techniques.\n"
        "- 'mix': Integrates knowledge graph and vector retrieval."
        "  - Uses both structured (KG) and unstructured (vector) information\n"
        "  - Provides comprehensive answers by analyzing relationships and context\n"
        "  - Supports image content through HTML img tags\n"
        "  - Allows control over retrieval depth via top_k parameter",
    )


class InsightModel(BaseModel):
    domain_knowledge: str = Field(..., description="Insight from the private domain knowledge")


class HandoffParamsModel(BaseModel):
    endpoint: str = Field(..., description="Endpoint to hand off to")
    path: str = Field(default="/{goal}", description="Path to append to the endpoint")
    method: str = Field("POST", description="HTTP method to use for the request")
    params: dict[str, Any] = Field(default_factory=dict, description="Parameters to pass in the request")


class DelegateParamsModel(BaseModel):
    target_peer_id: str = Field(..., description="Target peer ID for P2P delegation")
    goal: str = Field(..., description="Goal to delegate")
    plan: dict[str, Any] | None = Field(default=None, description="Optional plan to execute")
</file>

<file path="praxis_sdk/agents/utils.py">
from importlib.metadata import EntryPoint, entry_points
from typing import Any

from pydantic import BaseModel, Field, create_model

from praxis_sdk.agents.const import EntrypointGroup

TYPE_MAPPING: dict[str, type] = {
    "string": str,
    "integer": int,
    "number": float,
    "boolean": bool,
    "object": dict,
    "array": list,
    "null": type(None),
}


def get_entry_points(group: str) -> list[EntryPoint]:
    entrypoints = entry_points(group=group)
    return list(entrypoints)


def get_entrypoint(
    group: EntrypointGroup, target_entrypoint: str = "target", default_entrypoint: str = "basic"
) -> EntryPoint | None:
    entrypoints = get_entry_points(group.group_name)
    for ep in entrypoints:
        if ep.name == target_entrypoint:
            return ep

    for ep in entrypoints:
        if ep.name == default_entrypoint:
            return ep

    return None


def create_pydantic_model_from_json_schema(
    klass: str, schema: dict[str, Any], base_klass: type[BaseModel] | None = None
) -> type[BaseModel]:
    """Create a Pydantic model from a JSON schema."""
    fields = {}
    for prop_name, prop_info in schema["properties"].items():
        field_type = prop_info.get("type", "default")  # if no type, then it's the default?
        py_type = None
        if field_type == "default" or prop_name in ["properties", "required", "default", "additionalProperties"]:
            continue
        if field_type == "array":
            item_type = prop_info["items"]["type"]
            if item_type == "object":
                py_type = list[create_pydantic_model_from_json_schema(f"{klass}_{prop_name}", prop_info["items"])]
            else:
                py_type = list[TYPE_MAPPING.get(item_type)]
        elif field_type == "object":
            if prop_info.get("properties", None):
                py_type = create_pydantic_model_from_json_schema(f"{klass}_{prop_name}", prop_info)
            elif prop_info.get("$ref"):
                # NOTE: We probably need to make this more robust
                ref_info = schema["properties"].get(prop_info["$ref"].split("/")[-1])
                py_type = create_pydantic_model_from_json_schema(f"{klass}_{prop_name}", ref_info)
            elif prop_info.get("additionalProperties", {}).get("$ref", None):
                ref_info = schema["properties"].get(prop_info["additionalProperties"]["$ref"].split("/")[-1])
                py_type = dict[str, create_pydantic_model_from_json_schema(f"{klass}_{prop_name}", ref_info)]
            else:
                raise Exception(f"Object Error, {py_type} {prop_name} for {field_type}")
        elif TYPE_MAPPING.get(field_type):
            py_type = TYPE_MAPPING[field_type]

        if py_type is None:
            raise Exception(f"Error, {py_type} for {field_type}")

        default = prop_info.get("default", ...) if prop_name in schema.get("required", []) else ...
        description = prop_info.get("description", "")
        fields[prop_name] = (py_type, Field(default, description=description))

    return create_model(klass, __base__=base_klass, **fields)
</file>

<file path="tests/p2p/test_p2p_manager.py">
import threading
from unittest.mock import MagicMock, patch

import pytest


def test_init(p2p_manager, p2p_config):
    """Test initialization of P2PManager."""
    assert p2p_manager.config == p2p_config
    assert p2p_manager._libp2p_node is None
    assert p2p_manager._thread is None
    assert p2p_manager._running is False
    assert isinstance(p2p_manager._shutdown_event, threading.Event)


def test_getstate(p2p_manager):
    """Test serialization with __getstate__."""
    state = p2p_manager.__getstate__()
    assert "_libp2p_node" not in state
    assert "_thread" not in state
    assert "_running" not in state
    assert "_shutdown_event" not in state
    assert "config" in state


def test_setstate(p2p_manager):
    """Test deserialization with __setstate__."""
    state = {"config": p2p_manager.config}
    p2p_manager.__setstate__(state)
    assert p2p_manager.config == state["config"]
    assert p2p_manager._libp2p_node is None
    assert p2p_manager._thread is None
    assert p2p_manager._running is False
    assert isinstance(p2p_manager._shutdown_event, threading.Event)


def test_node_property_not_initialized(p2p_manager):
    """Test node property raises exception when not initialized."""
    with pytest.raises(RuntimeError, match="libp2p node is not initialized yet"):
        assert p2p_manager.node


def test_node_property_initialized(p2p_manager):
    """Test node property returns libp2p node when initialized."""
    mock_node = MagicMock()
    p2p_manager._libp2p_node = mock_node
    assert p2p_manager.node == mock_node


@patch("trio.run")
def test_run_in_thread(mock_trio_run, p2p_manager):
    """Test _run_in_thread method calls trio.run with _start."""
    p2p_manager._run_in_thread()
    mock_trio_run.assert_called_once_with(p2p_manager._start)


@patch("threading.Thread")
@pytest.mark.asyncio
async def test_start(mock_thread, p2p_manager):
    """Test start method initializes and starts a thread."""
    # Mock thread instance
    mock_thread_instance = MagicMock()
    mock_thread.return_value = mock_thread_instance

    # Call start
    await p2p_manager.start()

    # Verify thread was created and started
    mock_thread.assert_called_once_with(target=p2p_manager._run_in_thread, daemon=True)
    mock_thread_instance.start.assert_called_once()
    assert p2p_manager._running is True


@patch("threading.Thread")
@pytest.mark.asyncio
async def test_start_already_running(mock_thread, p2p_manager):
    """Test start method does nothing when already running."""
    p2p_manager._running = True
    await p2p_manager.start()
    mock_thread.assert_not_called()


@pytest.mark.asyncio
async def test_shutdown_not_running(p2p_manager):
    """Test shutdown when not running."""
    p2p_manager._running = False
    await p2p_manager.shutdown()
    # Nothing should happen, just verify it doesn't error


@patch.object(threading.Event, "set")
@pytest.mark.asyncio
async def test_shutdown(mock_event_set, p2p_manager):
    """Test shutdown sets event and cleans up."""
    # Setup
    mock_thread = MagicMock()
    p2p_manager._thread = mock_thread
    p2p_manager._running = True
    p2p_manager._libp2p_node = MagicMock()

    # Test
    await p2p_manager.shutdown()

    # Verify
    mock_event_set.assert_called_once()
    mock_thread.join.assert_called_once_with(timeout=10)
    assert p2p_manager._libp2p_node is None
    assert p2p_manager._running is False
</file>

<file path="tests/test_sdk.py">
import datetime
from unittest.mock import MagicMock, patch

import pytest

import praxis_sdk.agents.ray_entrypoint as ray_entrypoint
from praxis_sdk.agents.config import BasicAgentConfig
from praxis_sdk.agents.const import ExtraQuestions, Intents
from praxis_sdk.agents.models import AgentModel, InsightModel


class TestBaseAgent:
    @pytest.fixture(autouse=True)
    def setup_agent(self):
        # Patch all external dependencies at the class level for all tests
        with (
            patch.object(ray_entrypoint, "executor_builder") as mock_executor_builder,
            patch.object(ray_entrypoint, "prompt_builder") as mock_prompt_builder,
            patch.object(ray_entrypoint, "ai_registry_builder") as mock_ai_registry_builder,
            patch.object(ray_entrypoint, "light_rag_builder") as mock_lightrag_builder,
            patch.object(ray_entrypoint, "memory_builder") as mock_memory_builder,
        ):
            self.mock_executor = MagicMock()
            self.mock_prompt = MagicMock()
            self.mock_ai_registry = MagicMock()
            self.mock_lightrag = MagicMock()
            self.mock_memory = MagicMock()

            mock_executor_builder.return_value = self.mock_executor
            mock_prompt_builder.return_value = self.mock_prompt
            mock_ai_registry_builder.return_value = self.mock_ai_registry
            mock_lightrag_builder.return_value = self.mock_lightrag
            mock_memory_builder.return_value = self.mock_memory

            config = BasicAgentConfig()
            self.agent = ray_entrypoint.BaseAgent(config)
            yield

    def test_get_past_interactions(self):
        self.mock_memory.read.return_value = [{"foo": "bar"}]
        result = self.agent.get_past_interactions("some_goal")
        assert result == [{"foo": "bar"}]
        self.mock_memory.read.assert_called_with(key="some_goal")

    def test_store_interaction(self):
        goal = "my_goal"
        plan = {"step": 1}
        result = MagicMock()
        context = MagicMock()
        result.model_dump.return_value = {"result": 123}
        context.model_dump.return_value = {"foo": "bar"}

        self.agent.store_interaction(goal, plan, result, context)
        args, kwargs = self.mock_memory.store.call_args
        stored = kwargs["interaction"] if "interaction" in kwargs else args[1]
        assert stored["goal"] == goal
        assert stored["plan"] == plan
        assert stored["result"] == {"result": 123}
        assert stored["context"] == {"foo": "bar"}

    def test_get_relevant_insights(self):
        self.mock_lightrag.post.return_value = {"texts": [{"text": "insight1"}, {"text": "insight2"}]}
        insights = self.agent.get_relevant_insights("goal")
        assert isinstance(insights[0], InsightModel)
        assert insights[0].domain_knowledge == "insight1"

    def test_store_knowledge(self):
        self.mock_lightrag.post.return_value = {"status": "success"}
        result = self.agent.store_knowledge("file.txt", "content")
        assert result == {"status": "success"}
        self.mock_lightrag.post.assert_called_once()

    def test_get_most_relevant_agents(self):
        self.mock_ai_registry.post.return_value = [{"name": "agent1", "description": "desc", "version": "1.0.0"}]
        agents = self.agent.get_most_relevant_agents("goal")
        assert isinstance(agents[0], AgentModel)
        assert agents[0].name == "agent1"

    @patch("praxis_sdk.agents.ray_entrypoint.requests.get")
    def test_get_most_relevant_tools(self, mock_requests_get):
        agent_data = AgentModel(name="agent1", description="desc", version="1.0.0")
        self.mock_ai_registry.post.return_value = [
            {
                "name": "tool1",
                "openai_function_spec": {
                    "function": {"name": "foo", "description": "bar", "parameters": {}, "output": {}}
                },
            }
        ]
        mock_requests_get.return_value.json.return_value = {"skills": []}
        mock_requests_get.return_value.raise_for_status = MagicMock()

        tools = self.agent.get_most_relevant_tools("goal", [agent_data])
        assert isinstance(tools, list)
        assert any(t.name == "return-answer-tool" for t in tools)

    def test_generate_plan(self):
        self.mock_executor.generate_plan.return_value = "workflow"
        plan = self.agent.generate_plan("goal", [], [], [], [])
        self.mock_executor.generate_plan.assert_called_once()
        assert plan == "workflow"

    def test_chat_chitchat(self):
        self.mock_executor.classify_intent.return_value = Intents.CHIT_CHAT
        self.mock_executor.chat.return_value = "Hello!"
        self.mock_prompt.generate_intent_classifier_prompt.return_value = "intent_prompt"
        self.mock_prompt.generate_chat_prompt.return_value = "chat_prompt"

        # Make sure chat context returns empty so a new message is added
        self.mock_memory.read.return_value = {"results": []}
        self.mock_memory.store = MagicMock()

        resp = self.agent.chat("Hi!", None)
        assert resp.response_text == "Hello!"
        assert resp.action == Intents.CHIT_CHAT

    def test_chat_change_settings(self):
        self.mock_executor.classify_intent.return_value = Intents.CHANGE_SETTINGS
        self.mock_prompt.generate_intent_classifier_prompt.return_value = "intent_prompt"
        self.mock_memory.read.return_value = {"results": []}
        self.mock_memory.store = MagicMock()

        resp = self.agent.chat("Change settings", None)
        assert resp.response_text == ExtraQuestions.WHICH_SETTINGS
        assert resp.action == Intents.CHANGE_SETTINGS

    def test_chat_add_knowledge(self):
        self.mock_executor.classify_intent.return_value = Intents.ADD_KNOWLEDGE
        self.mock_prompt.generate_intent_classifier_prompt.return_value = "intent_prompt"
        self.mock_memory.read.return_value = {"results": []}
        self.mock_memory.store = MagicMock()

        resp = self.agent.chat("Add this info", None)
        assert resp.response_text == ExtraQuestions.WHAT_INFO
        assert resp.action == Intents.ADD_KNOWLEDGE

    def test_chat_action_add_knowledge_success(self):
        self.mock_memory.read.return_value = {"results": []}
        self.mock_memory.store = MagicMock()
        self.mock_lightrag.post.return_value = {"status": "success"}

        resp = self.agent.chat("Some info", Intents.ADD_KNOWLEDGE)
        assert resp.response_text == "Information added to the knowledge base."
        assert resp.action is None

    def test_chat_action_add_knowledge_fail(self):
        self.mock_memory.read.return_value = {"results": []}
        self.mock_memory.store = MagicMock()
        self.mock_lightrag.post.return_value = {"status": "error"}

        resp = self.agent.chat("Some info", Intents.ADD_KNOWLEDGE)
        assert "failed" in resp.response_text.lower()

    def test_chat_action_change_settings(self):
        self.mock_memory.read.return_value = {"results": []}
        self.mock_memory.store = MagicMock()
        self.mock_executor.reconfigure.return_value = {"foo": "bar"}
        self.mock_prompt.generate_reconfigure_prompt.return_value = "prompt"
        self.mock_prompt.generate_plan_prompt.return_value = "prompt"
        self.mock_prompt.generate_chat_prompt.return_value = "prompt"
        self.mock_prompt.generate_intent_classifier_prompt.return_value = "prompt"

        resp = self.agent.chat("Update config", Intents.CHANGE_SETTINGS)
        assert "updated" in resp.response_text.lower() or "sorry" in resp.response_text.lower()

    def test_get_chat_context(self):
        self.mock_memory.read.return_value = {"results": []}
        res = self.agent.get_chat_context("uuid1")
        assert isinstance(res, list)

    def test_store_chat_context(self):
        uuid_ = "uuid1"
        messages = [{"memory": "foo", "created_at": datetime.datetime.now()}]
        self.mock_memory.store = MagicMock()
        self.agent.store_chat_context(uuid_, messages)
        self.mock_memory.store.assert_called_once()

    def test_run_workflow(self):
        self.agent.workflow_runner = MagicMock()
        wf = MagicMock()
        ctx = MagicMock()
        self.agent.run_workflow(wf, ctx)
        self.agent.workflow_runner.run.assert_called_once_with(wf, ctx)

    # NOTE: Old HTTP handoff test removed as handoff method was deprecated.
    # New P2P handoff implementation is tested in tests/p2p/libp2p/test_handoff.py
</file>

<file path=".pre-commit-config.yaml">
# .pre-commit-config.yaml
repos:
-   repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.6.0 #
    hooks:
    -   id: check-yaml
        files: \.(yaml|yml)$
    -   id: end-of-file-fixer
        files: \.py$
    -   id: trailing-whitespace
        files: \.py$
    -   id: check-merge-conflict
    -   id: check-added-large-files

-   repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.11.12
    hooks:
    -   id: ruff
        args: [--fix, --exit-non-zero-on-fix]
        files: \.py$
    -   id: ruff-format
        files: \.py$

-   repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.16.0
    hooks:
    -   id: mypy
        args: [--strict]
        files: \.py$
        additional_dependencies: [
            "pydantic>=2.0.0",
            "fastapi>=0.100.0",
            "types-requests",
            "types-redis",
            "types-pyyaml"
        ]
</file>

<file path="CODE_OF_CONDUCT.md">
# Contributor Covenant Code of Conduct

## Our Pledge

In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.

## Our Standards

Examples of behavior that contributes to creating a positive environment include:

* Using welcoming and inclusive language
* Being respectful of differing viewpoints and experiences
* Gracefully accepting constructive criticism
* Focusing on what is best for the community
* Showing empathy towards other community members

Examples of unacceptable behavior by participants include:

* The use of sexualized language or imagery and unwelcome sexual attention or advances
* Trolling, insulting/derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or electronic address, without explicit permission
* Other conduct which could reasonably be considered inappropriate in a professional setting

## Our Responsibilities

Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.

Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.

## Scope

This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.

Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html

[homepage]: https://www.contributor-covenant.org
</file>

<file path="docker-compose.yaml">
services:
  redis:
    image: redislabs/redisearch:latest
    ports:
      - "6380:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5

  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5

  lightrag:
    image: ghcr.io/hkuds/lightrag:latest
    ports:
      - "8080:8080"
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      STORAGE_URL: s3://${MINIO_BUCKET}
      STORAGE_ENDPOINT: http://minio:9000
      STORAGE_ACCESS_KEY: ${MINIO_ROOT_USER}
      STORAGE_SECRET_KEY: ${MINIO_ROOT_PASSWORD}
    depends_on:
      postgres:
        condition: service_healthy
      minio:
        condition: service_healthy

volumes:
  pgdata:
  minio-data:
</file>

<file path=".github/workflows/reusable.publish-agent.yml">
name: Reusable - Agent Publish

on:
  workflow_call:
    inputs:
      path:
        required: true
        type: string
      agent_name:
        required: true
        type: string
    secrets:
      REGISTRY_TOKEN:
        required: true
      OCI_REGISTRY_TOKEN:
        required: true

jobs:
  publish-python:
    uses: ./.github/workflows/reusable.publish-python.yml
    with:
      path: ${{ inputs.path }}
    secrets:
      REGISTRY_TOKEN: ${{ secrets.REGISTRY_TOKEN }}

  check_dockerfile:
    runs-on: ubuntu-latest
    outputs:
      has_dockerfile: ${{ steps.check_file.outputs.has_dockerfile }}
      image_tag: ${{ steps.build_tag.outputs.image_tag }}
    steps:
      - uses: actions/checkout@v2
      - id: check_file
        run: |
          if [ -f "${{ inputs.path }}/Dockerfile" ]; then
            echo "has_dockerfile=true" >> $GITHUB_OUTPUT
          else
            echo "has_dockerfile=false" >> $GITHUB_OUTPUT
          fi

      - id: build_tag
        run: |
          TAG_NAME=${GITHUB_REF_NAME//\//-}
          # Assuming version tags formatted as v* or similar
          if [[ "$TAG_NAME" =~ ^v(.+) ]]; then
            VERSION=v${BASH_REMATCH[1]}
          else
            VERSION=$TAG_NAME
          fi
          echo "image_tag=$VERSION" >> $GITHUB_OUTPUT

  publish-docker:
    needs: [check_dockerfile, publish-python]
    if: needs.check_dockerfile.outputs.has_dockerfile == 'true'
    uses: ./.github/workflows/reusable.publish-docker.yml
    with:
      path: ${{ inputs.path }}
      image_name: agents
      dockerfile: ${{ inputs.path }}/Dockerfile
      tag_name: ${{ needs.check_dockerfile.outputs.image_tag }}
    secrets:
      OCI_REGISTRY_TOKEN: ${{ secrets.OCI_REGISTRY_TOKEN }}
</file>

<file path="praxis_sdk/agents/p2p/const.py">
from libp2p.custom_types import (
    TProtocol,
)

PROTOCOL_CARD: TProtocol = TProtocol("/ai-agent/card/1.0.0")
PROTOCOL_HANDOFF: TProtocol = TProtocol("/ai-agent/handoff/1.0.0")
</file>

<file path="praxis_sdk/agents/p2p/handlers.py">
from __future__ import annotations

import datetime
import json
from typing import TYPE_CHECKING

import httpx
from loguru import logger

from praxis_sdk.agents.p2p.const import PROTOCOL_CARD, PROTOCOL_HANDOFF

if TYPE_CHECKING:
    from libp2p.network.stream.net_stream import INetStream


async def handle_card(stream: INetStream) -> None:
    peer_id_str = str(stream.muxed_conn.peer_id)
    timestamp = datetime.datetime.now(datetime.timezone.utc).isoformat()

    logger.info(f"[{timestamp}] Received card request on {PROTOCOL_CARD} from peer {peer_id_str}")

    card_url = "http://localhost:8000/card"

    try:
        async with httpx.AsyncClient(timeout=2.0) as client:
            response = await client.get(card_url)
            response.raise_for_status()

        await stream.write(response.content)
        logger.info(f"[{timestamp}] Sent card data to peer {peer_id_str} for protocol {PROTOCOL_CARD}")

    except httpx.HTTPStatusError as e:
        logger.error(
            f"[{timestamp}] HTTP error for {PROTOCOL_CARD} from {peer_id_str}: {e.response.status_code} - {e.response.text}"
        )
        error_msg = f'{{"error":"HTTP error: {e.response.status_code}","code":{e.response.status_code}}}'.encode()
        await stream.write(error_msg)
    except httpx.RequestError as e:
        logger.error(
            f"[{timestamp}] Request error for {PROTOCOL_CARD} from {peer_id_str}: {type(e).__name__} - {str(e)}"
        )
        await stream.write(b'{"error":"Request to /card failed or timed out","code":504}')  # 504 Gateway Timeout
    except Exception as e:
        logger.error(f"[{timestamp}] Unexpected error processing {PROTOCOL_CARD} for {peer_id_str}: {e}", exc_info=True)
        await stream.write(b'{"error":"Internal server error","code":500}')
    finally:
        try:
            await stream.close()
        except Exception as e:
            logger.error(f"[{timestamp}] Error closing stream for {PROTOCOL_CARD} with peer {peer_id_str}: {e}")
        logger.info(f"[{timestamp}] Closed stream for {PROTOCOL_CARD} with peer {peer_id_str}")


async def handle_handoff(stream: INetStream) -> None:
    peer_id_str = str(stream.muxed_conn.peer_id)
    timestamp = datetime.datetime.now(datetime.timezone.utc).isoformat()

    logger.info(f"[{timestamp}] Received handoff request on {PROTOCOL_HANDOFF} from peer {peer_id_str}")

    try:
        data = await stream.read()
        if not data:
            raise ValueError("Empty payload received")

        payload = json.loads(data.decode("utf-8"))

        method = payload.get("method", "POST")
        path = payload.get("path")
        params = payload.get("params", {})
        input_data = payload.get("input_data")

        if not path:
            raise ValueError("Path is required in handoff payload")

        formatted_path = path.format(**params) if params else path
        request_url = f"http://localhost:8000/{formatted_path.lstrip('/')}"

        logger.info(f"[{timestamp}] Making {method.upper()} request to {request_url} for peer {peer_id_str}")

        async with httpx.AsyncClient(timeout=10.0) as client:
            request_kwargs = {"method": method.upper(), "url": request_url}

            if input_data is not None:
                if isinstance(input_data, (dict, list)):
                    request_kwargs["json"] = input_data
                else:
                    request_kwargs["content"] = str(input_data).encode("utf-8")

            response = await client.request(**request_kwargs)
            response.raise_for_status()

            await stream.write(response.content)
            logger.info(f"[{timestamp}] Successfully handled handoff request from peer {peer_id_str}")

    except json.JSONDecodeError as e:
        logger.error(f"[{timestamp}] JSON decode error for handoff from {peer_id_str}: {str(e)}")
        error_msg = json.dumps({"error": f"Invalid JSON: {str(e)}", "code": 400}).encode()
        await stream.write(error_msg)

    except ValueError as e:
        logger.error(f"[{timestamp}] Validation error for handoff from {peer_id_str}: {str(e)}")
        error_msg = json.dumps({"error": str(e), "code": 400}).encode()
        await stream.write(error_msg)

    except httpx.HTTPStatusError as e:
        logger.error(
            f"[{timestamp}] HTTP error for handoff from {peer_id_str}: {e.response.status_code} - {e.response.text}"
        )
        error_msg = json.dumps(
            {"error": f"HTTP error: {e.response.status_code}", "code": e.response.status_code}
        ).encode()
        await stream.write(error_msg)

    except httpx.RequestError as e:
        logger.error(f"[{timestamp}] Request error for handoff from {peer_id_str}: {type(e).__name__} - {str(e)}")
        error_msg = json.dumps({"error": f"Request to {path} failed or timed out", "code": 504}).encode()
        await stream.write(error_msg)

    except Exception as e:
        logger.error(f"[{timestamp}] Unexpected error processing handoff for {peer_id_str}: {e}", exc_info=True)
        error_msg = json.dumps({"error": "Internal server error", "code": 500}).encode()
        await stream.write(error_msg)

    finally:
        try:
            await stream.close()
        except Exception as e:
            logger.error(f"[{timestamp}] Error closing stream for handoff with peer {peer_id_str}: {e}")
        logger.info(f"[{timestamp}] Closed stream for handoff with peer {peer_id_str}")
</file>

<file path="praxis_sdk/agents/p2p/manager.py">
"""Isolated P2P module to avoid serialization issues."""

import threading
from typing import Any

import trio
from loguru import logger

from praxis_sdk.agents.p2p.config import P2PConfig, get_p2p_config


class P2PManager:
    """Manager for P2P operations that isolates libp2p imports."""

    def __init__(self, config: P2PConfig) -> None:
        self.config = config
        self._libp2p_node: Any = None
        self._thread: threading.Thread | None = None
        self._running: bool = False
        self._shutdown_event: threading.Event = threading.Event()

    def __getstate__(self) -> object:
        odict = self.__dict__.copy()

        for k in ["_libp2p_node", "_thread", "_running", "_shutdown_event"]:
            del odict[k]

        return odict

    def __setstate__(self, state: dict[str, Any]) -> None:
        self.__dict__.update(state)
        self._libp2p_node = None
        self._thread = None
        self._running = False
        self._shutdown_event = threading.Event()

    @property
    def node(self) -> Any:
        if self._libp2p_node is not None:
            return self._libp2p_node
        raise RuntimeError("libp2p node is not initialized yet. Call start()")

    def _run_in_thread(self) -> None:
        """Run the P2P node in a separate thread using Trio."""
        try:
            trio.run(self._start)
        except Exception as e:
            logger.error(f"Error in P2P thread: {e}")
            raise
        finally:
            logger.info("P2P thread exiting")
            self._running = False

    async def _start(self) -> None:
        """Trio-based implementation of the P2P node."""
        from multiaddr import Multiaddr

        from praxis_sdk.agents.p2p.libp2p import LibP2PNode

        node = LibP2PNode(self.config)
        host = await node.initialize()
        self._libp2p_node = node

        async with host.run(listen_addrs=[Multiaddr("/ip4/0.0.0.0/tcp/9001")]), trio.open_nursery() as nursery:
            await node.setup_listener(nursery)

            while not self._shutdown_event.is_set():
                try:
                    success = await node.connect_to_relay()
                    if not success:
                        await trio.sleep(10)
                        continue

                    while not self._shutdown_event.is_set():
                        await trio.sleep(10)

                except Exception as e:
                    logger.error(f"Error in p2p node loop: {e}")
                    await trio.sleep(10)

    async def start(self) -> None:
        """Start the P2P node in a separate thread."""
        if self._running:
            logger.warning("P2P manager is already running")
            return

        self._running = True
        self._shutdown_event.clear()

        self._thread = threading.Thread(target=self._run_in_thread, daemon=True)
        self._thread.start()

        logger.info("P2P manager started in separate thread")

    async def shutdown(self):
        """Shutdown libp2p node."""
        if not self._running:
            logger.warning("P2P manager is not running")
            return

        logger.info("Shutting down P2P manager...")
        self._shutdown_event.set()

        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=10)

        self._libp2p_node = None
        self._running = False
        logger.info("P2P shutdown completed.")


def get_p2p_manager() -> P2PManager:
    return P2PManager(config=get_p2p_config())
</file>

<file path="praxis_sdk/agents/abc.py">
from abc import ABC, abstractmethod
from collections.abc import Sequence
from typing import Any

import pydantic

from praxis_sdk.agents.models import AgentModel, ToolModel, Workflow


class AbstractAgentCard(pydantic.BaseModel):
    """Abstract interface for agent cards."""


class AbstractAgentSkill(pydantic.BaseModel):
    """Abstract interface for agent skills."""


class AbstractAgentParamsModel(pydantic.BaseModel):
    """Abstract interface for agent params model."""


class AbstractAgentInputModel(pydantic.BaseModel):
    """Abstract interface for agent input model."""


class AbstractAgentOutputModel(pydantic.BaseModel):
    """Abstract interface for agent output model."""


class AbstractChatResponse(pydantic.BaseModel):
    response_text: str
    action: str | None = None


class BaseAgentInputModel(AbstractAgentInputModel): ...


class BaseAgentOutputModel(AbstractAgentOutputModel): ...


class AbstractExecutor(ABC):
    """Abstract interface for agent execution engines."""

    @abstractmethod
    def generate_plan(self, prompt: Any, **kwargs) -> Workflow:
        """Generate a plan based on a prompt and additional parameters.

        Args:
            prompt: The prompt to use for planning
            **kwargs: Additional parameters to use in planning

        Returns:
            A dictionary mapping step IDs to Task objects representing the plan

        """

    @abstractmethod
    def chat(self, prompt: Any, **kwargs) -> str:
        """Generate a chat response based on a prompt and additional parameters.

        Args:
            prompt: The prompt to use for further chat conversation
            **kwargs: Additional parameters to use in chatting

        Returns:
            An str with response

        """

    @abstractmethod
    def classify_intent(self, prompt: Any, **kwargs) -> str:
        """Classifies user intent based on a prompt and additional parameters.

        Args:
            prompt: The prompt to use for intent classification
            **kwargs: Additional parameters to use in chatting

        Returns:
            An str with intent

        """

    @abstractmethod
    def reconfigure(self, prompt: Any, **kwargs) -> dict:
        """Create new config based on the current config and the user request.

        Args:
            prompt: The prompt to use for updating config
            **kwargs: Additional parameters to use in chatting

        Returns:
            A dict with the updated config

        """


class AbstractPromptBuilder(ABC):
    """Abstract interface for prompt building components."""

    @abstractmethod
    def generate_plan_prompt(self, *args, **kwargs) -> Any:
        """Generate a prompt for plan generation.

        Args:
            *args: Positional arguments for prompt generation
            **kwargs: Keyword arguments for prompt generation

        Returns:
            A prompt object that can be used by an executor

        """

    @abstractmethod
    def generate_chat_prompt(self, *args, **kwargs) -> Any:
        """Generate a prompt for chat.

        Args:
            *args: Positional arguments for prompt generation
            **kwargs: Keyword arguments for prompt generation

        Returns:
            A prompt object that can be used by an executor

        """

    @abstractmethod
    def generate_intent_classifier_prompt(self, *args, **kwargs) -> Any:
        """Generate a prompt for intent classification.

        Args:
            *args: Positional arguments for prompt generation
            **kwargs: Keyword arguments for prompt generation

        Returns:
            A prompt object that can be used by an executor

        """

    @abstractmethod
    def generate_reconfigure_prompt(self, *args, **kwargs) -> Any:
        """Generate a prompt for reconfiguration.

        Args:
            *args: Positional arguments for prompt generation
            **kwargs: Keyword arguments for prompt generation

        Returns:
            A prompt object that can be used by an executor

        """


class AbstractWorkflowRunner(ABC):
    """Abstract interface for workflow execution engines."""

    @abstractmethod
    async def run(
        self,
        dag_spec: Workflow,
        context: AbstractAgentInputModel | None = None,
        async_mode: bool = False,
    ) -> AbstractAgentOutputModel:
        """Execute a workflow plan.

        Args:
            dag_spec: A workflow specification to execute
            context: Optional context data for execution
            async_mode: Whether to run in async mode

        Returns:
            The result of executing the plan

        """

    @classmethod
    @abstractmethod
    def start_daemon(cls) -> None:
        """Start the workflow runner engine."""

    @classmethod
    @abstractmethod
    def stop_daemon(cls) -> None:
        """Stop the workflow runner engine."""

    @abstractmethod
    def run_background_workflows(self, *args, **kwargs) -> None:
        """Run static workflows in the workflow runner engine."""

    @abstractmethod
    async def list_workflows(self, *args, **kwargs) -> None:
        """List all workflows in the workflow runner engine."""

    @abstractmethod
    def reconfigure(self, config: dict[str, Any]) -> None:
        """Reconfigure the agent with new settings.

        Args:
            config: New configuration settings

        """


class AbstractAgent(ABC):
    """Abstract base class for agent implementations."""

    @abstractmethod
    async def handle(
        self,
        goal: str,
        plan: Workflow | None = None,
        context: AbstractAgentInputModel | None = None,
    ) -> AbstractAgentOutputModel:
        """Handle an incoming request.

        Args:
            goal: The goal to achieve
            plan: An optional existing plan to use or modify
            context: An optional input schema for the agent

        Returns:
            The result of achieving the goal

        """

    @abstractmethod
    def get_most_relevant_agents(self, goal: str) -> list[AgentModel]:
        """Find the most relevant agents for a goal.

        Args:
            goal: The goal to achieve

        Returns:
            A list of the most relevant agents for the goal

        """

    @abstractmethod
    def get_most_relevant_tools(self, goal: str) -> list[ToolModel]:
        """Find the most relevant tools for a goal.

        Args:
            goal: The goal to achieve

        Returns:
            A list of the most relevant tools for the goal

        """

    @abstractmethod
    def generate_plan(
        self, goal: str, agents: Sequence[AgentModel], tools: Sequence[ToolModel], plan: dict | None = None
    ) -> Workflow:
        """Generate a plan for achieving a goal.

        Args:
            goal: The goal to achieve
            agents: Available agents to use in the plan
            tools: Available tools to use in the plan
            plan: An optional existing plan to use or modify

        Returns:
            A dictionary mapping step IDs to Task objects representing the plan

        """

    @abstractmethod
    def chat(
        self,
        user_prompt: str,
        **kwargs,
    ) -> AbstractChatResponse:
        pass

    @abstractmethod
    async def run_workflow(self, plan: Workflow) -> Any:
        """Execute a workflow plan.

        Args:
            plan: A dictionary mapping step IDs to Task objects

        Returns:
            The result of executing the plan

        """

    @abstractmethod
    def reconfigure(self, config: dict[str, Any]) -> None:
        """Reconfigure the agent with new settings.

        Args:
            config: New configuration settings

        """


class AbstractAgentP2PManager(ABC):
    """A manager for P2P communication between agents."""

    @property
    @abstractmethod
    def node(self) -> Any: ...

    @abstractmethod
    async def start(self) -> None: ...

    @abstractmethod
    async def shutdown(self) -> None: ...

    @abstractmethod
    async def delegate(self, target_peer_id: str, payload: dict) -> dict: ...
</file>

<file path="tests/p2p/libp2p/test_p2pnode.py">
import os
from unittest.mock import AsyncMock, MagicMock, patch

import pytest
from libp2p.crypto.keys import KeyPair

from praxis_sdk.agents.p2p.config import P2PConfig
from praxis_sdk.agents.p2p.libp2p.node import LibP2PNode


@pytest.fixture
def config():
    return P2PConfig(
        keystore_path="/tmp/test_keystore", relay_addr="/ip4/127.0.0.1/tcp/8888/p2p/QmTest", noise_key="test_noise_key"
    )


@pytest.fixture
def mock_keypair():
    return MagicMock(spec=KeyPair)


@pytest.fixture
def node(config):
    with patch("praxis_sdk.agents.p2p.libp2p.node.load_or_create_node_key") as mock_load_key:
        mock_load_key.return_value = MagicMock(spec=KeyPair)
        return LibP2PNode(config)


class TestLibP2PNode:
    def test_init(self, config):
        with patch("praxis_sdk.agents.p2p.libp2p.node.load_or_create_node_key") as mock_load_key:
            mock_load_key.return_value = MagicMock(spec=KeyPair)
            node = LibP2PNode(config)

            assert node.config == config
            assert node.host is None
            assert node.shutdown_requested is False
            assert isinstance(node.keypair, MagicMock)
            mock_load_key.assert_called_once_with(os.path.join(config.keystore_path, "node.key"))

    def test_init_keypair(self, node, config):
        with patch("praxis_sdk.agents.p2p.libp2p.node.load_or_create_node_key") as mock_load_key:
            mock_load_key.return_value = MagicMock(spec=KeyPair)

            node._init_keypair("custom.key")

            mock_load_key.assert_called_with(os.path.join(config.keystore_path, "custom.key"))
            assert isinstance(node.keypair, MagicMock)

    def test_init_host(self, node):
        with (
            patch("praxis_sdk.agents.p2p.libp2p.node.new_host") as mock_new_host,
            patch("praxis_sdk.agents.p2p.libp2p.node.decode_noise_key") as mock_decode,
            patch("praxis_sdk.agents.p2p.libp2p.node.NoiseTransport") as mock_noise,
        ):
            mock_decode.return_value = "decoded_noise_key"
            mock_host = MagicMock()
            mock_new_host.return_value = mock_host

            result = node._init_host()

            mock_decode.assert_called_once_with(node.config.noise_key)
            mock_noise.assert_called_once()
            mock_new_host.assert_called_once()
            assert result == mock_host

    @pytest.mark.asyncio
    async def test_initialize(self, node):
        mock_host = MagicMock()
        mock_host.get_id.return_value = "test_id"
        mock_host.get_addrs.return_value = ["addr1", "addr2"]

        with (
            patch.object(node, "_init_host", return_value=mock_host),
            patch("praxis_sdk.agents.p2p.libp2p.node.CircuitV2Protocol") as mock_protocol,
            patch("praxis_sdk.agents.p2p.libp2p.node.CircuitV2Transport") as mock_transport,
        ):
            result = await node.initialize()

            mock_host.set_stream_handler.assert_called_once()
            mock_protocol.assert_called_once_with(mock_host)
            mock_transport.assert_called_once()
            assert result == mock_host
            assert node.host == mock_host

    @pytest.mark.asyncio
    async def test_connect_to_relay_success(self, node):
        mock_host = MagicMock()
        mock_host.connect = AsyncMock()
        node.host = mock_host

        with patch("praxis_sdk.agents.p2p.libp2p.node.info_from_p2p_addr") as mock_info:
            result = await node.connect_to_relay()

            mock_info.assert_called_once()
            mock_host.connect.assert_called_once()
            assert result is True

    @pytest.mark.asyncio
    async def test_connect_to_relay_failure(self, node):
        mock_host = MagicMock()
        mock_host.connect = AsyncMock(side_effect=Exception("Connection failed"))
        node.host = mock_host

        with patch("praxis_sdk.agents.p2p.libp2p.node.info_from_p2p_addr"):
            result = await node.connect_to_relay()

            assert result is False

    @pytest.mark.asyncio
    async def test_setup_listener(self, node):
        mock_transport = MagicMock()
        mock_listener = MagicMock()
        mock_listener.listen = AsyncMock()
        mock_transport.create_listener.return_value = mock_listener
        node.transport = mock_transport

        mock_nursery = MagicMock()

        with patch("praxis_sdk.agents.p2p.libp2p.node.handle_card"):
            await node.setup_listener(mock_nursery)

            mock_transport.create_listener.assert_called_once()
            mock_listener.listen.assert_called_once_with(None, mock_nursery)

    def test_init_host_with_noise_protocol(self, node):
        with (
            patch("praxis_sdk.agents.p2p.libp2p.node.new_host") as mock_new_host,
            patch("praxis_sdk.agents.p2p.libp2p.node.decode_noise_key") as mock_decode,
            patch("praxis_sdk.agents.p2p.libp2p.node.NoiseTransport") as mock_noise,
        ):
            mock_decode.return_value = "decoded_noise_key"
            mock_host = MagicMock()
            mock_new_host.return_value = mock_host

            # Ensure noise_key is set
            node.config.noise_key = "test_noise_key"

            result = node._init_host()

            # Verify noise protocol was configured
            mock_decode.assert_called_once_with("test_noise_key")
            mock_noise.assert_called_once_with(libp2p_keypair=node.keypair, noise_privkey="decoded_noise_key")
            mock_new_host.assert_called_once()
            assert result == mock_host
</file>

<file path="tests/p2p/libp2p/test_p2putils.py">
import os
import tempfile
from base64 import b64encode
from pathlib import Path

from libp2p.crypto.ed25519 import Ed25519PrivateKey, create_new_key_pair
from libp2p.crypto.keys import KeyPair

from praxis_sdk.agents.p2p.libp2p.utils import decode_noise_key, load_or_create_node_key


class TestP2PUtils:
    def test_load_or_create_node_key_creates_new_key(self):
        # Test with a path that doesn't exist
        with tempfile.TemporaryDirectory() as tmpdirname:
            seed_path = os.path.join(tmpdirname, "non_existent_dir", "seed_file")

            # Ensure the file doesn't exist initially
            assert not Path(seed_path).exists()

            # Call the function which should create the key
            key_pair = load_or_create_node_key(seed_path)

            # Verify file was created
            assert Path(seed_path).exists()

            # Verify return type
            assert isinstance(key_pair, KeyPair)

    def test_load_or_create_node_key_loads_existing_key(self):
        # Test with a path that exists
        with tempfile.TemporaryDirectory() as tmpdirname:
            seed_path = os.path.join(tmpdirname, "seed_file")

            # Create a seed file
            seed = os.urandom(32)
            Path(seed_path).write_bytes(seed)

            # Call the function which should load the existing key
            key_pair = load_or_create_node_key(seed_path)

            # Verify the key_pair matches what we expect from the seed
            expected_key_pair = create_new_key_pair(seed)
            assert key_pair.private_key.to_bytes() == expected_key_pair.private_key.to_bytes()
            assert key_pair.public_key.to_bytes() == expected_key_pair.public_key.to_bytes()

    def test_decode_noise_key(self):
        # Generate a valid Ed25519 key
        key_pair = create_new_key_pair(os.urandom(32))
        private_key_bytes = key_pair.private_key.to_bytes()

        # Encode it as we would in the application
        encoded_key = b64encode(private_key_bytes).decode()

        # Use our function to decode it
        decoded_key = decode_noise_key(encoded_key)

        # Verify type and content
        assert isinstance(decoded_key, Ed25519PrivateKey)
        assert decoded_key.to_bytes() == private_key_bytes
</file>

<file path="tests/p2p/conftest.py">
import pytest

from praxis_sdk.agents.p2p.config import P2PConfig
from praxis_sdk.agents.p2p.manager import P2PManager


@pytest.fixture
def p2p_config():
    """Fixture that provides a P2P configuration for testing."""
    return P2PConfig(relay_addr="/ip4/127.0.0.1/tcp/9000/p2p/TEST_RELAY_PEER_ID")


@pytest.fixture
def p2p_manager(p2p_config):
    return P2PManager(config=p2p_config)
</file>

<file path=".env.example">
OPENAI_API_KEY=


POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=db


MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin
MINIO_BUCKET=lightbucket

AI_REGISTRY_URL=
KNOWLEDGE_BASE_URL=http://lightrag:8080
REDIS_HOST=redis
P2P_RELAY_ADDR=/ip4/127.0.0.1/tcp/9000/p2p/RELAY_PEER_ID
</file>

<file path=".devcontainer/Dockerfile">
# Note: You can use any Debian/Ubuntu based image you want.
FROM mcr.microsoft.com/devcontainers/base:bookworm

# [Optional] Uncomment this section to install additional OS packages.
# RUN apt-get update && export DEBIAN_FRONTEND=noninteractive \
#     && apt-get -y install --no-install-recommends <your-package-list-here>

RUN apt update && \
    apt -y --no-install-recommends install libgmp3-dev python3-pip && \
    pip3 install --upgrade pip && \
    pip3 install poetry && \
    rm -rf /var/lib/apt/lists/*
</file>

<file path=".github/workflows/release.python-agent.yml">
name: Release praxis-sdk-agents

on:
  workflow_dispatch:
    inputs:
      part:
        required: true
        type: choice
        description: "part"
        default: patch
        options:
          - major
          - minor
          - patch

concurrency: "release"

jobs:
  publish:
    # Allow the job to fetch a GitHub ID token
    permissions:
      id-token: write
      contents: write
    uses: ./.github/workflows/reusable.release.yml
    with:
      working_directory: .
      part: ${{ github.event.inputs.part }}
    secrets:
      RELEASE_TOKEN: ${{ secrets.RELEASE_TOKEN }}
</file>

<file path=".github/workflows/reusable.publish-docker.yml">
name: Reusable - Docker Publish to OCI Registry

on:
  workflow_call:
    inputs:
      image_name:
        required: true
        type: string
      dockerfile:
        required: true
        type: string
      path:
        required: true
        type: string
      tag_name:
        required: false
        type: string
    secrets:
      OCI_REGISTRY_TOKEN:
        required: true

env:
  OCI_REGISTRY: harbor.dev.prxs.ai/docker

jobs:
  build:
    permissions:
      id-token: write
      contents: read

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2

    - name: Login to Docker registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.OCI_REGISTRY }}
        username: ${{ vars.OCI_REGISTRY_USER }}
        password: ${{ secrets.OCI_REGISTRY_TOKEN }}

    - name: Build image registry name
      id: build_repo_name
      run: |
        echo "OCI_REPOSITORY=$OCI_REGISTRY/${{ inputs.image_name }}" >> $GITHUB_ENV

    - name: Build image tag
      id: build_tag
      run: |
        # Function to slugify a string to RFC 1123 compliant format
        slugify() {
          local word="$1"
          # Transform to lowercase
          word="${word,,}"
          # Replace non-alphanumeric characters with dashes
          word="$(echo "$word" | sed -E 's/[^a-z0-9-]+/-/g')"
          # Trim dashes from start and end
          word="$(echo "$word" | sed -E 's/^-+|-+$//g')"
          # Smart truncate to a maximum length of 50 characters
          if [ "${#word}" -gt 50 ]; then
            local index=50
            while [ "$index" -gt 0 ]; do
              if [ "${word:index:1}" == "-" ]; then
                breakAmazon ECR
              fi
              index=$((index - 1))
            done
            if [ "$index" -eq 0 ]; then
              index=50
            fi
            word="${word:0:$index}"
          fi
          echo "$word"
        }

        # First check if a tag_name input is provided
        if [ -n "${{ inputs.tag_name }}" ]; then
          VERSION=${{ inputs.tag_name }}
        # For pull requests, use GITHUB_HEAD_REF
        elif [ -n "$GITHUB_HEAD_REF" ]; then
          BRANCH_NAME=${GITHUB_HEAD_REF//\//-}
          VERSION=$(slugify $BRANCH_NAME)
        # For direct branch pushes
        elif [[ "$GITHUB_REF_TYPE" == "branch" ]]; then
          BRANCH_NAME=${GITHUB_REF_NAME//\//-}
          VERSION=$(slugify $BRANCH_NAME)
        # For tags that have specific version format
        elif [[ "$GITHUB_REF_NAME" =~ ^.*\/${{ inputs.image_name }}-v(.+) ]]; then
          VERSION=v${BASH_REMATCH[1]}
        # Fallback for other references
        else
          TAG_NAME=${GITHUB_REF_NAME//\//-}
          VERSION=$(slugify $TAG_NAME)
        fi

        echo "IMAGE_TAG=$VERSION" >> $GITHUB_ENV

    - name: Build Docker image
      run: |
        docker build \
          --file ${{ inputs.dockerfile }} \
          -t $OCI_REPOSITORY:${IMAGE_TAG} \
          ${{ inputs.path }}

    - name: Push to OCI
      run: |
        docker push --all-tags $OCI_REPOSITORY
</file>

<file path="praxis_sdk/agents/orchestration/runner.py">
import uuid
from typing import Any

import ray
from ray import workflow
from ray.runtime_env import RuntimeEnv

from praxis_sdk.agents import abc
from praxis_sdk.agents.const import EntrypointGroup
from praxis_sdk.agents.models import Workflow, WorkflowStep
from praxis_sdk.agents.orchestration.config import BasicWorkflowConfig
from praxis_sdk.agents.orchestration.utils import get_workflows_from_files
from praxis_sdk.agents.utils import get_entry_points


@ray.remote
def generate_request_id() -> str:
    # Generate a unique idempotency token.
    return uuid.uuid4().hex


class DAGRunner(abc.AbstractWorkflowRunner):
    def __init__(self, config: BasicWorkflowConfig):
        self.config = config

    def reconfigure(self, config: dict[str, Any]) -> None:
        """Reconfigure the agent with new settings.

        Args:
            config: New configuration settings

        """
        self.config = BasicWorkflowConfig(**config)

    @classmethod
    def start_daemon(cls: "DAGRunner", include_failed=False) -> None:
        pass  # Ensure the method is not empty if all lines are commented

    @classmethod
    def stop_daemon(cls: "DAGRunner") -> None:
        #  TODO(team): Stop all workflows  # https://github.com/project/issues/124
        pass

    def run_background_workflows(
        self,
    ) -> None:
        """Run static workflows in the workflow runner engine."""
        wfs = get_workflows_from_files()

        for _, wf_dict in wfs.items():
            wf = Workflow(**wf_dict)
            if wf.id in self.config.WORKFLOWS_TO_RUN and self.config.WORKFLOWS_TO_RUN[wf.id].enabled:
                self.run(wf, async_mode=True)

    async def list_workflows(self, status: str | None = None):
        wf_dict = {}
        for wf_id, _ in workflow.list_all(status):
            wf_dict[wf_id] = workflow.get_metadata(wf_id)
        return wf_dict

    def create_step(self, step: WorkflowStep):
        """Create a remote function for a step."""
        runtime_env = RuntimeEnv(pip=[step.tool.render_pip_dependency()], env_vars=step.env_vars)

        @ray.workflow.options(checkpoint=True)
        @ray.remote(
            runtime_env=runtime_env,
            max_retries=self.config.WORKFLOW_STEP_MAX_RETRIES,
            retry_exceptions=True,
        )
        def get_tool_entrypoint_wrapper(*args, **kwargs):
            entry_points = get_entry_points(EntrypointGroup.TOOL_ENTRYPOINT)
            try:
                tool = entry_points[step.tool.package_name].load()
            except KeyError as exc:
                raise ValueError(f"Tool {step.tool.package_name} not found in entry points") from exc
            return workflow.continuation(
                tool.options(runtime_env=RuntimeEnv(env_vars=step.env_vars)).bind(*args, **kwargs)
            )

        return get_tool_entrypoint_wrapper, step.args

    async def run(self, dag_spec: Workflow, context: Any = None, async_mode: bool = False) -> Any:
        """Run the DAG using Ray Workflows."""
        steps = {}

        for step in dag_spec.steps:
            steps[step.task_id] = self.create_step(step)

        if not steps:
            return None

        last_task_id = list(steps.keys())[-1]

        @ray.remote
        def workflow_executor(request_id: str) -> Any:
            step_results = {}

            for task_id, (task, task_args) in sorted(steps.items()):
                result = task.bind(**task_args)
                step_results[task_id] = result

                if task_id == last_task_id:
                    return workflow.continuation(result)

            last_result = list(step_results.values())[-1] if step_results else None
            return workflow.continuation(last_result)

        func = workflow.run
        if async_mode:
            func = workflow.run_async

        return func(
            workflow_executor.bind(generate_request_id.bind()),
            workflow_id=dag_spec.id,
            metadata={"dag_spec": dag_spec.model_dump()},
        )


def dag_runner(config: BasicWorkflowConfig) -> DAGRunner:
    return DAGRunner(config)
</file>

<file path="praxis_sdk/agents/bootstrap.py">
from contextlib import asynccontextmanager
from typing import Any

from fastapi import FastAPI
from ray.serve.deployment import Deployment

from praxis_sdk.agents import abc
from praxis_sdk.agents.card import card_builder
from praxis_sdk.agents.orchestration import workflow_builder
from praxis_sdk.agents.p2p import p2p_builder


def bootstrap_main(agent_cls: type[abc.AbstractAgent]) -> type[Deployment]:
    """Bootstrap a main agent with the necessary components to be able to run as a Ray Serve deployment."""
    from ray import serve

    runner: abc.AbstractWorkflowRunner = workflow_builder()
    card: abc.AbstractAgentCard = card_builder()
    p2p: abc.AbstractAgentP2PManager = p2p_builder()

    @asynccontextmanager
    async def lifespan(app: FastAPI):
        # launch some tasks on app start
        runner.start_daemon()
        runner.run_background_workflows()

        agent_instance = app.state.agent_instance
        if hasattr(agent_instance, "p2p_manager"):
            await agent_instance.p2p_manager.start()
        yield
        runner.stop_daemon()

        if hasattr(agent_instance, "p2p_manager"):
            await agent_instance.p2p_manager.shutdown()

    app = FastAPI(lifespan=lifespan)

    @serve.deployment
    @serve.ingress(app)
    class Agent(agent_cls):
        def __init__(self, *args, **kwargs):
            super().__init__(*args, **kwargs)
            self.p2p_manager = p2p
            app.state.agent_instance = self

        @property
        def workflow_runner(self):
            return runner

        @property
        def agent_card(self):
            return card

        @app.get("/card")
        async def get_card(self):
            return self.agent_card

        @app.get("/workflows")
        async def list_workflows(self, status: str | None = None):
            return await self.workflow_runner.list_workflows(status)

        @app.post("/{goal}")
        async def handle(self, goal: str, plan: dict | None = None, context: Any = None):
            return await super().handle(goal, plan, context)

    return Agent
</file>

<file path="praxis_sdk/agents/ray_entrypoint.py">
import datetime
import uuid
from collections.abc import Sequence
from logging import getLogger
from typing import Any
from urllib.parse import urljoin

import requests
from ray.serve.deployment import Application

from praxis_sdk.agents import abc, const
from praxis_sdk.agents.ai_registry import ai_registry_builder
from praxis_sdk.agents.bootstrap import bootstrap_main
from praxis_sdk.agents.card.models import AgentCard
from praxis_sdk.agents.config import BasicAgentConfig, get_agent_config
from praxis_sdk.agents.domain_knowledge import light_rag_builder
from praxis_sdk.agents.langchain import executor, executor_builder
from praxis_sdk.agents.memory import memory_builder
from praxis_sdk.agents.models import (
    AgentModel,
    ChatMessageModel,
    GoalModel,
    InsightModel,
    MemoryModel,
    ToolModel,
    Workflow,
)
from praxis_sdk.agents.prompt import prompt_builder

logger = getLogger(__name__)


class BaseAgent(abc.AbstractAgent):
    """Base default implementation for all agents."""

    workflow_runner: abc.AbstractWorkflowRunner
    prompt_builder: abc.AbstractPromptBuilder
    agent_executor: abc.AbstractExecutor

    def __init__(self, config: BasicAgentConfig, *args, **kwargs):
        self.config = config
        self.agent_executor = executor_builder()
        self.prompt_builder = prompt_builder()

        # ---------- AI Registry ----------#
        self.ai_registry_client = ai_registry_builder()

        # ---------- LightRAG Memory -------#
        self.lightrag_client = light_rag_builder()

        # ---------- Redis Memory ----------#
        self.memory_client = memory_builder()

    async def handle(
        self,
        goal: str,
        plan: dict | None = None,
        context: abc.BaseAgentInputModel | None = None,
    ) -> abc.BaseAgentOutputModel:
        """Handle the most important endpoint of MAS.

        It handles all requests made by handoff from other agents or by user.

        If a predefined plan is provided, it skips plan generation and executes the plan directly.
        Otherwise, it follows the standard logic to generate a plan and execute it.
        """
        if plan:
            result = await self.run_workflow(plan, context)
            self.store_interaction(goal, plan, result, context)
            return result

        insights = self.get_relevant_insights(goal)
        past_interactions = self.get_past_interactions(goal)
        agents = self.get_most_relevant_agents(goal)
        tools = self.get_most_relevant_tools(goal, agents)

        plan = self.generate_plan(
            goal=goal,
            agents=agents,
            tools=tools,
            insights=insights,
            past_interactions=past_interactions,
            plan=None,
        )
        result = await self.run_workflow(plan, context)
        self.store_interaction(goal, plan, result, context)
        return result

    def get_past_interactions(self, goal: str) -> list[dict]:
        return self.memory_client.read(key=goal)

    def store_interaction(
        self,
        goal: str,
        plan: dict,
        result: abc.BaseAgentOutputModel,
        context: abc.BaseAgentInputModel | None = None,
    ) -> None:
        interaction = MemoryModel(
            goal=goal, plan=plan, result=result.model_dump(), context=context.model_dump() if context else None
        )
        self.memory_client.store(key=goal, interaction=interaction.model_dump())

    def store_chat_context(
        self,
        uuid: str,
        messages: list[dict],
    ) -> None:
        normalized_messages = [msg if isinstance(msg, dict) else msg.model_dump() for msg in messages]
        self.memory_client.store(key=f"chat:{uuid}", interaction=normalized_messages)

    def get_chat_context(self, uuid: str) -> list[dict]:
        results = self.memory_client.read(key=f"chat:{uuid}").get("results")
        print(f"Fetched {len(results)} results")
        return results

    def get_relevant_insights(self, goal: str) -> list[InsightModel]:
        """Retrieve relevant insights from LightRAG memory for the given goal."""
        response = self.lightrag_client.post(
            endpoint=self.lightrag_client.endpoints.query,
            json={
                "query": goal,
                "mode": "naive",
            },
        )
        texts = response.get("texts", [])
        return [InsightModel(domain_knowledge=text["text"]) for text in texts if "text" in text]

    def store_knowledge(self, filename: str | None, content: str) -> dict:
        data = {"content": content}
        if filename:
            data["filename"] = filename

        return self.lightrag_client.post(
            endpoint=self.lightrag_client.endpoints.insert,
            json=data,
        )

    def get_most_relevant_agents(self, goal: str) -> list[AgentModel]:
        """Find the most useful agents for the given goal."""
        response = self.ai_registry_client.post(
            endpoint=self.ai_registry_client.endpoints.find_agents,
            json=GoalModel(goal=goal).model_dump(),
        )

        if not response:
            return []

        return [AgentModel(**agent) for agent in response]
        # return [AgentModel(
        #     name = 'example-agent',
        #     description = 'This is an agent to handoff the any goal',
        #     version = '0.1.0'
        # )]

    def get_most_relevant_tools(self, goal: str, agents: list[AgentModel]) -> list[ToolModel]:
        """Find the most useful tools for the given goal."""
        response = self.ai_registry_client.post(
            endpoint=self.ai_registry_client.endpoints.find_tools,
            json=GoalModel(goal=goal).model_dump(),
        )
        tools = [ToolModel(**tool) for tool in response]

        for agent in agents:
            if not agent.peer_id:
                continue

            card_url = urljoin(agent.endpoint, "/card")
            try:
                resp = requests.get(card_url)
                resp.raise_for_status()

                data = resp.json()
                card = AgentCard(**data)
            except Exception as e:
                logger.warning(f"Failed to fetch card from agent {agent} at {card_url}: {e}")
                continue
            for skill in card.skills:
                func_name = f"{agent.name}_p2p_delegate".replace("-", "_")
                spec = {
                    "type": "function",
                    "function": {
                        "name": func_name,
                        "description": f"Delegate task to agent '{agent.name}' via P2P for skill: {skill.description}",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "target_peer_id": {
                                    "type": "string",
                                    "description": "Target peer ID for delegation",
                                    "default": agent.peer_id,
                                },
                                "goal": {"type": "string", "description": "Goal to delegate"},
                                "plan": {"type": "object", "description": "Optional plan to execute", "default": None},
                            },
                            "required": ["target_peer_id", "goal"],
                        },
                        "output": skill.output_model.model_json_schema(),
                    },
                }
                tools.append(
                    ToolModel(
                        name="p2p_delegate_tool",
                        version="0.1.0",
                        default_parameters={"target_peer_id": agent.peer_id},
                        parameters_spec=skill.params_model.model_json_schema(),
                        openai_function_spec=spec,
                    )
                )

        return tools + [
            ToolModel(
                name="return-answer-tool",
                version="0.1.2",
                openai_function_spec={
                    "type": "function",
                    "function": {
                        "name": "return_answer_tool",
                        "description": "Returns the input as output.",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "answer": {
                                    "type": "string",
                                    "description": "The answer in JSON string.",
                                    "default": '{"result": 42}',
                                }
                            },
                            "required": ["answer"],
                        },
                        "output": {
                            "type": "object",
                            "properties": {
                                "result": {
                                    "type": "string",
                                    "description": "Returns the input as output in JSON string.",
                                }
                            },
                        },
                    },
                },
            ),
        ]

    def generate_plan(
        self,
        goal: str,
        agents: Sequence[AgentModel],
        tools: Sequence[ToolModel],
        past_interactions: Sequence[MemoryModel],
        insights: Sequence[InsightModel],
        plan: dict | None = None,
    ) -> Workflow:
        """Generate a plan for the given goal."""
        return self.agent_executor.generate_plan(
            self.prompt_builder.generate_plan_prompt(system_prompt=self.config.system_prompt),
            available_functions=tools,
            available_agents=agents,
            goal=goal,
            past_interactions=past_interactions,
            insights=insights,
            plan=plan,
        )

    def chat(
        self,
        user_prompt: str,
        action: str | None,
        session_uuid: str | None = None,
    ) -> executor.ChatResponse:
        if not session_uuid:
            session_uuid = str(uuid.uuid4())

        prior_context = self.get_chat_context(session_uuid)
        chat_history = [
            ChatMessageModel(role="user", content=m.get("memory", ""), timestamp=m.get("created_at"))
            for m in prior_context
        ]

        chat_history.append(
            ChatMessageModel(
                role="user",
                content=user_prompt,
                timestamp=datetime.datetime.now(datetime.timezone.utc),
            )
        )

        self.store_chat_context(session_uuid, chat_history)

        # ------ Reconfigure Agent ----- #
        if action == const.Intents.CHANGE_SETTINGS:
            existing_config = str(self.config)
            print(f"Current config: {existing_config}")

            updated_config = self.agent_executor.reconfigure(
                prompt=self.prompt_builder.generate_reconfigure_prompt(
                    system_prompt=self.config.system_prompt,
                    user_prompt=user_prompt,
                    existing_config=existing_config,
                ),
                user_message=user_prompt,
                existing_config=existing_config,
                system_prompt=self.config.system_prompt,
            )

            if updated_config:
                print(f"Updated config: {updated_config}")
                self.reconfigure(updated_config)
                response = executor.ChatResponse(
                    response_text="Settings updated successfully.",
                    action=None,
                    session_uuid=session_uuid,
                )
            else:
                response = executor.ChatResponse(
                    response_text="Sorry, I couldn't parse the settings you want to change. Please try again.",
                    action=const.Intents.CHANGE_SETTINGS,
                    session_uuid=session_uuid,
                )
            chat_history.append(
                ChatMessageModel(
                    role="assistant",
                    content=response.response_text,
                    timestamp=datetime.datetime.now(datetime.timezone.utc),
                )
            )
            self.store_chat_context(session_uuid, chat_history)
            return response

        # ------ Add Knowledge to Knowledge Base ----- #
        if action == const.Intents.ADD_KNOWLEDGE:
            print(f"Trying to add to knowledge base: {user_prompt}")
            result: dict = self.store_knowledge(filename=None, content=user_prompt)

            # Default message
            response_text = "I failed to add information to the knowledge base."
            if result and result.get("status") and result["status"] == "success":
                response_text = "Information added to the knowledge base."

            response = executor.ChatResponse(
                response_text=response_text,
                action=None,
                session_uuid=session_uuid,
            )
            chat_history.append(
                ChatMessageModel(
                    role="assistant",
                    content=response.response_text,
                    timestamp=datetime.datetime.now(datetime.timezone.utc),
                )
            )
            self.store_chat_context(session_uuid, chat_history)
            return response

        # ------ Classify Intent ----- #
        if action is None:
            intent = self.agent_executor.classify_intent(
                prompt=self.prompt_builder.generate_intent_classifier_prompt(
                    system_prompt=self.config.system_prompt,
                    user_prompt=user_prompt,
                ),
                user_message=user_prompt,
                context=[m.content for m in chat_history],
            )
            if intent == const.Intents.CHANGE_SETTINGS:
                print(f"Intent: {intent}")
                response = executor.ChatResponse(
                    response_text=const.ExtraQuestions.WHICH_SETTINGS,
                    action=const.Intents.CHANGE_SETTINGS,
                    session_uuid=session_uuid,
                )
                chat_history.append(
                    ChatMessageModel(
                        role="assistant",
                        content=response.response_text,
                        timestamp=datetime.datetime.now(datetime.timezone.utc),
                    )
                )
                self.store_chat_context(session_uuid, chat_history)
                return response

            if intent == const.Intents.ADD_KNOWLEDGE:
                print(f"Intent: {intent}")
                response = executor.ChatResponse(
                    response_text=const.ExtraQuestions.WHAT_INFO,
                    action=const.Intents.ADD_KNOWLEDGE,
                    session_uuid=session_uuid,
                )
                chat_history.append(
                    ChatMessageModel(
                        role="assistant",
                        content=response.response_text,
                        timestamp=datetime.datetime.now(datetime.timezone.utc),
                    )
                )
                self.store_chat_context(session_uuid, chat_history)
                return response

        # ------ Chit Chat ----- #
        print(f"Intent: {const.Intents.CHIT_CHAT}")
        chat_context_str = "\n".join([m.content for m in chat_history[-10:]]) if chat_history else ""
        assistant_reply = self.agent_executor.chat(
            prompt=self.prompt_builder.generate_chat_prompt(
                system_prompt=self.config.system_prompt,
                user_prompt=user_prompt,
                context=chat_context_str,
            ),
            user_message=user_prompt,
            context=chat_context_str,
        )
        response = executor.ChatResponse(
            response_text=assistant_reply,
            action=const.Intents.CHIT_CHAT,
            session_uuid=session_uuid,
        )
        chat_history.append(
            ChatMessageModel(
                role="assistant",
                content=response.response_text,
                timestamp=datetime.datetime.now(datetime.timezone.utc),
            )
        )
        self.store_chat_context(session_uuid, chat_history)
        return response

    async def run_workflow(
        self,
        plan: Workflow,
        context: abc.BaseAgentInputModel | None = None,
    ) -> abc.BaseAgentOutputModel:
        return await self.workflow_runner.run(plan, agent=self, context=context)

    def reconfigure(self, config: dict[str, Any]):
        pass


def agent_builder(args: dict) -> Application:
    return bootstrap_main(BaseAgent).bind(config=get_agent_config(**args))
</file>

<file path="entrypoint.py">
from praxis_sdk.agents.const import EntrypointGroup
from praxis_sdk.agents.utils import get_entrypoint

app = get_entrypoint(EntrypointGroup.AGENT_ENTRYPOINT).load()
</file>

<file path="README.md">
# praxis SDK Agents

`BaseAgent` is a foundational agent implementation designed to be used in a modular Multi-Agent System (MAS) environment. It supports planning, execution, memory, intent recognition, and agent/tool coordination.

## Project Structure

```
praxis-sdk-agents/
├── .github/              # GitHub configuration and templates
├── base-agent/           # Base agent template
├── docs/                 # Documentation
├── src/                  # Source code
├── tests/                # Test files
├── pyproject.toml        # Project configuration
└── poetry.lock           # Dependency lock file
```

## Features

- Goal-oriented planning and execution
- Integration with AI Registry and LightRAG for knowledge retrieval
- Redis-based memory storage for interactions and chat sessions
- Support for tool and agent discovery
- Reconfigurable via chat prompts
- Supports contextual chat with memory
- Can add knowledge to its internal knowledge base

## Components

- **Executor**: Generates plans and classifies intents
- **Prompt Builder**: Generates prompts for various internal tasks
- **AI Registry Client**: Finds relevant agents and tools
- **LightRAG Client**: Provides domain-specific insights
- **Memory Client**: Stores and retrieves historical data

## Key Methods

- `handle(goal, plan, context)`: Main entrypoint to process goals
- `generate_plan(...)`: Creates a workflow based on available resources
- `chat(user_prompt, action, session_uuid)`: Handles interactive chat with optional configuration or knowledge update actions
- `store_knowledge(filename, content)`: Adds new information to the knowledge base

## Requirements

* Python 3.10+
* [Poetry](https://python-poetry.org/) for dependency management
* Ray Serve
* Redis
* LightRAG and AI Registry services

## Installation

```bash
poetry install
```

## Running Tests

```bash
poetry run pytest
```

## Development Setup

### Installing & Running Pre-commit

This repository uses pre-commit hooks to ensure code quality and consistency. Pre-commit automatically runs formatting, linting, and type checking before each commit.

#### Installation

1. **Install dependencies** (includes pre-commit, ruff, and mypy):
   ```bash
   poetry install --with dev
   ```

2. **Install pre-commit hooks**:
   ```bash
   poetry run pre-commit install
   ```

3. **Optional: Install pre-push hooks** (recommended):
   ```bash
   poetry run pre-commit install --hook-type pre-push
   ```

#### Usage

- **Automatic**: Pre-commit runs automatically on `git commit`
- **Manual**: Run on all files with:
  ```bash
  poetry run pre-commit run --all-files
  ```
- **Skip hooks** (not recommended):
  ```bash
  git commit --no-verify
  ```

#### What it checks

- **YAML syntax** and file formatting
- **Trailing whitespace** and end-of-file fixes
- **Merge conflict** markers
- **Large files** prevention
- **Ruff linting & formatting** (replaces black, flake8, isort)
- **MyPy type checking** with strict mode

## Adding New Packages

The agent is intended to be deployed as part of a Ray Serve application and can be extended with custom workflows, tools, and domain knowledge.

To add a new agent package:
1. Create a new directory under `src/`
2. Follow the BaseAgent structure and patterns
3. Add tests under `tests/`
4. Update dependencies in `pyproject.toml` if needed

## Support

### Getting Help

If you need help or have questions about the praxis SDK Agents:

- **GitHub Issues**: For bug reports and feature requests, please use our [issue templates](https://github.com/prxs-ai/praxis-sdk-agents/issues/new/choose)
- **GitHub Discussions**: For general questions and community discussions, visit our [discussions page](https://github.com/prxs-ai/praxis-sdk-agents/discussions)
- **Documentation**: Check our [contributing guide](docs/CONTRIBUTING.md) for development workflows

### Response Time

We aim to respond to issues and discussions within **48 hours** during business days. Please be patient as our maintainers are volunteers.

### Breaking Changes Policy

We follow semantic versioning and maintain backward compatibility:

- **MAJOR version bumps**: We will maintain backward compatibility for at least **6 months** before removing deprecated features
- **MINOR version bumps**: Only add new features, no breaking changes
- **PATCH version bumps**: Bug fixes and security updates only

All breaking changes will be clearly documented in our [CHANGELOG.md](CHANGELOG.md) and announced in advance.

## Maintainers

This project is maintained by:

- **Technical Lead**: [@hyp0cr4t](https://github.com/hyp0cr4t)
- **Primary Maintainer**: [@0xDevZip](https://github.com/0xDevZip)
- **Core Maintainer**: [@ruthuwjwb](https://github.com/ruthuwjwb)
- **Infrastructure Maintainer**: [@hexavor](https://github.com/hexavor)

### Maintainer Responsibilities

- Review and merge pull requests
- Triage and respond to issues
- Release new versions
- Maintain project roadmap and direction

### Becoming a Maintainer

We welcome new maintainers! If you're interested in helping maintain this project:

1. **Contribute regularly**: Submit quality PRs and help with issue triage
2. **Show commitment**: Demonstrate sustained involvement over 3+ months
3. **Express interest**: Reach out to existing maintainers via GitHub Discussions
4. **Onboarding**: Current maintainers will provide access and guidance

### Maintainer Rotation

- Maintainers may step down at any time by notifying the team
- Inactive maintainers (6+ months) will be asked about their continued involvement
- New maintainers require approval from at least 2 existing maintainers

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
</file>

<file path=".gitignore">
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

*.so

.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST


*.manifest
*.spec

pip-log.txt
pip-delete-this-directory.txt

htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

.scrapy

docs/_build/

.pybuilder/
target/

.ipynb_checkpoints

profile_default/
ipython_config.py

.pdm.toml
.pdm-python
.pdm-build/

__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

*.sage.py

.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

.spyderproject
.spyproject

.ropeproject

/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

.pyre/

.pytype/

cython_debug/

.abstra/


.ruff_cache/

.pypirc

.cursorignore
.cursorindexingignore

# Pyre stuff:
.vscode/

# P2P stuff:
keys/
</file>

<file path="praxis_sdk/agents/card/config.py">
from functools import lru_cache

import pydantic
from pydantic_settings import BaseSettings, SettingsConfigDict


class CardConfig(BaseSettings):
    name: str = "base-agent"
    version: str = "0.1.0"
    description: str = "This is a base agent. It provides a base implementation for all other agents."

    model_config = SettingsConfigDict(
        env_file=".env",
        env_prefix="AGENT_CARD_",
        env_file_encoding="utf-8",
        extra=pydantic.Extra.ignore,
    )


@lru_cache
def get_card_config() -> CardConfig:
    return CardConfig()
</file>

<file path="Dockerfile">
ARG BASE_IMAGE=rayproject/ray:2.42.1-py310-cpu

FROM ${BASE_IMAGE} as builder

USER root

# Install poetry and dependencies
RUN pip install poetry poetry-plugin-export && \
    poetry config virtualenvs.create false

# Copy dependency files
COPY pyproject.toml poetry.lock* /build/
WORKDIR /build

# Only generate requirements.txt from poetry
RUN poetry export -f requirements.txt --without-hashes --output requirements.txt

FROM ${BASE_IMAGE}

USER root

RUN apt update && \
    apt -y --no-install-recommends install libgmp3-dev gcc build-essential && \
    rm -rf /var/lib/apt/lists/*

# Install dependencies with a private registry
COPY --from=builder /build/requirements.txt ./requirements.txt
RUN pip install --no-cache-dir -r ./requirements.txt && \
    rm ./requirements.txt

# Set the environment variables
ENV PIP_EXTRA_INDEX_URL="https://packages.pypi.prxs.ai/simple/ https://agents.pypi.prxs.ai/simple/ https://tools.pypi.prxs.ai/simple/"

WORKDIR /serve_app

COPY ./praxis_sdk /serve_app/praxis_sdk
RUN touch /serve_app/praxis_sdk/__init__.py

COPY entrypoint.py /serve_app/entrypoint.py
</file>

<file path=".bumpversion.toml">
[tool.bumpversion]
current_version = "0.1.0"
message = "Bump version of praxis-sdk-agents: {current_version} → {new_version}"
commit = false
tag = false
tag_name = "v{new_version}"

[[tool.bumpversion.files]]
filename = "pyproject.toml"
search = "version = \"{current_version}\""
replace = "version = \"{new_version}\""

[[tool.bumpversion.files]]
filename = "praxis_sdk/agents/card/config.py"
search = "version: str = \"{current_version}\""
replace  = "version: str = \"{new_version}\""
</file>

<file path="pyproject.toml">
[project]
name = "praxis-sdk-agents"
version = "0.1.0"
description = "praxis SDK Agents"
authors = [{ name = "hyp0cr4t", email = "hyp0cr4t@icloud.com" }]
readme = "README.md"
requires-python = ">=3.10,<3.14"
dependencies = [
    "fastapi (>=0.115.8,<1.0.0)",
    "openai (>=1.63.2,<2.0.0)",
    "langchain (>=0.3.19,<0.4.0)",
    "jinja2 (>=3.1.5,<4.0.0)",
    "pydantic-settings (>=2.8.0,<3.0.0)",
    "langfuse (>=2.59.3,<3.0.0)",
    "langchain-openai (>=0.3.6,<0.4.0)",
    "mem0ai==0.1.67",
    "lightrag-hku==1.2.5",
    "redisvl (>=0.6.0,<0.7.0)",
    "libp2p @ git+https://github.com/hyp0cr4t/py-libp2p.git@feat/circuit-v2#egg=libp2p",
    "loguru (>=0.7.3,<0.8.0)",
    "trio-asyncio (>=0.15.0,<0.16.0)",
]

[tool.poetry]
packages = [{ include = "praxis_sdk" }]

[project.entry-points."agent.executor.config"]
basic = "praxis_sdk.agents.langchain.config:get_langchain_config"

[project.entry-points."agent.executor.entrypoint"]
basic = "praxis_sdk.agents.langchain.executor:agent_executor"

[project.entry-points."agent.prompt.config"]
basic = "praxis_sdk.agents.prompt.config:get_prompt_config"

[project.entry-points."agent.prompt.entrypoint"]
basic = "praxis_sdk.agents.prompt.builder:prompt_builder"

[project.entry-points."agent.workflow.config"]
basic = "praxis_sdk.agents.orchestration.config:get_workflow_config"

[project.entry-points."agent.workflow.entrypoint"]
basic = "praxis_sdk.agents.orchestration.runner:dag_runner"

[project.entry-points."agent.entrypoint"]
basic = "praxis_sdk.agents.ray_entrypoint:agent_builder"

[project.entry-points."ai.registry.config"]
basic = "praxis_sdk.agents.ai_registry.config:get_ai_registry_config"

[project.entry-points."ai.registry.entrypoint"]
basic = "praxis_sdk.agents.ai_registry.client:ai_registry_client"

[project.entry-points."domain.knowledge.config"]
basic = "praxis_sdk.agents.domain_knowledge.config:get_light_rag_config"

[project.entry-points."domain.knowledge.entrypoint"]
basic = "praxis_sdk.agents.domain_knowledge.client:light_rag_client"

[project.entry-points."memory.config"]
basic = "praxis_sdk.agents.memory.config:get_memory_config"

[project.entry-points."memory.entrypoint"]
basic = "praxis_sdk.agents.memory.client:memory_client"

[project.entry-points."card.entrypoint"]
basic = "praxis_sdk.agents.card.builder:get_agent_card"

[project.entry-points."p2p.entrypoint"]
basic = "praxis_sdk.agents.p2p.manager:get_p2p_manager"

[tool.poetry.group.dev.dependencies]
ray = { extras = ["serve"], version = "2.42.1" }
pytest = "^8.3.4"
pyarrow = "^19.0.1"
factory-boy = "^2.12.0"
pytest-trio = "^0.8.0"
pytest-asyncio = "^1.0.0"
pre-commit = "^4.2.0"
ruff = "^0.11.12"
mypy = "^1.16.0"

[build-system]
requires = ["poetry-core>=2.0.0,<3.0.0"]
build-backend = "poetry.core.masonry.api"

[tool.ruff]
line-length = 120
target-version = "py310"

[tool.ruff.lint]
select = ["ALL"]
ignore = [
    "BLE001",
    "F821",
    "PERF",
    "INP001",
    "A001",
    "PLW2901",
    "G",
    "E501",
    "PTH",
    "TRY",
    "ARG",
    "C",
    "ERA",
    "PLR",
    "DTZ",
    "S",
    "RUF",
    "PGH003",
    "PERF203",
    "ANN",
    "TRY401",
    "EM",
    "FBT",
    "TRY003",
    "D1",
    "D203",
    "D213",
    "G004",
    "FA",
    "COM812",
    "ISC001",
    "RUF001",
    "B904",
    "SLF001",
    "ASYNC110",   # ← Разрешает trio.sleep в while циклах
    "ASYNC210",   # ← Разрешает блокирующие HTTP в async функциях
    "ASYNC230",
    "FIX002",
    "T",        # ← Разрешает print() и pprint()
    "T201",     # ← Разрешает print()
    "T203",     # ← Разрешает pprint()
]

[tool.ruff.format]
quote-style = "double"

[tool.mypy]
python_version = "3.10"
# Максимально мягкие настройки для legacy кода
warn_return_any = false
warn_unused_configs = false
check_untyped_defs = false
disallow_untyped_defs = false
disallow_incomplete_defs = false
disallow_untyped_calls = false
disallow_any_generics = false
disallow_any_unimported = false
disallow_subclassing_any = false
warn_redundant_casts = false
warn_unused_ignores = false
strict_optional = false
strict_equality = false
ignore_missing_imports = true
ignore_errors = false
show_error_codes = true
follow_imports = "silent"

# Исключаем директории с тестами и legacy код
exclude = [
    "tests/",
    "build/",
    "dist/",
    "praxis_sdk/agents/ray_entrypoint.py",  # Много ошибок override
]

# Отключаем самые проблемные коды ошибок
disable_error_code = [
    "no-untyped-def",
    "no-untyped-call",
    "no-any-return",
    "misc",
    "type-arg",
    "unused-ignore",
    "override",
    "assignment",
    "arg-type",
    "call-overload",
    "return-value",
    "attr-defined",
    "name-defined",
    "call-arg",
    "var-annotated",
    "valid-type",
    "comparison-overlap",
    "unused-coroutine",
]

# Игнорируем распространенные ошибки для pydantic и других библиотек
[[tool.mypy.overrides]]
module = [
    "pydantic.*",
    "pydantic_settings.*",
    "ray.*",
    "libp2p.*",
    "multiaddr.*",
    "langchain.*",
    "langfuse.*",
]
ignore_errors = true

# Игнорируем ошибки в проблемных файлах
[[tool.mypy.overrides]]
module = [
    "praxis_sdk.agents.ray_entrypoint",
    "ray_entrypoint",
]
ignore_errors = true
</file>

</files>
